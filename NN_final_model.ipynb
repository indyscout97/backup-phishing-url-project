{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMsmB1OqoQO6"
   },
   "source": [
    "---\n",
    "\n",
    "# Keras Sequential Neural Network model to predict the probability of a phishing URL\n",
    "\n",
    "---\n",
    "\n",
    "### this notebook is of the final Keras model version that was decided on for this project\n",
    "### included are two different ways to build the same Keras model, along with predictions and cross validation results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you haven't used tensorflow before, uncomment below to install:\n",
    "\n",
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UjcFFKd7XM2",
    "outputId": "b320499b-fb46-4568-e56f-0f05d9ff51de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#load packages and libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import *\n",
    "from keras.utils.np_utils import *\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(\"Done Loading\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZJiz6GaoQO9"
   },
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "_p0zv7mq7p3R",
    "outputId": "a43c42a0-1cf7-4406-e6ea-26ac2e736279"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>qty_space_url</th>\n",
       "      <th>...</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>589</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3597</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  \\\n",
       "0            3               0                  0              1   \n",
       "1            5               0                  1              3   \n",
       "2            2               0                  0              1   \n",
       "3            4               0                  2              5   \n",
       "4            2               0                  0              0   \n",
       "\n",
       "   qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  \\\n",
       "0                     0              0           0            0   \n",
       "1                     0              3           0            2   \n",
       "2                     0              0           0            0   \n",
       "3                     0              0           0            0   \n",
       "4                     0              0           0            0   \n",
       "\n",
       "   qty_exclamation_url  qty_space_url  ...  qty_ip_resolved  qty_nameservers  \\\n",
       "0                    0              0  ...                1                2   \n",
       "1                    0              0  ...                1                2   \n",
       "2                    0              0  ...                1                2   \n",
       "3                    0              0  ...                1                2   \n",
       "4                    0              0  ...                1                2   \n",
       "\n",
       "   qty_mx_servers  ttl_hostname  tls_ssl_certificate  qty_redirects  \\\n",
       "0               0           892                    0              0   \n",
       "1               1          9540                    1              0   \n",
       "2               3           589                    1              0   \n",
       "3               0           292                    1              0   \n",
       "4               1          3597                    0              1   \n",
       "\n",
       "   url_google_index  domain_google_index  url_shortened  phishing  \n",
       "0                 0                    0              0         1  \n",
       "1                 0                    0              0         1  \n",
       "2                 0                    0              0         0  \n",
       "3                 0                    0              0         1  \n",
       "4                 0                    0              0         0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv(\"https://raw.githubusercontent.com/jwaldroop/phishing-url-project/main/dataset_full.csv\")\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxhItR4mUlyi"
   },
   "source": [
    "---\n",
    "\n",
    "# unit testing to remove negative values (there cannot be a negative url length, etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1KXuFC-sUk-e"
   },
   "outputs": [],
   "source": [
    "# Noticed a discrepancy in the data, some values are recorded as -1 even though it makes not practical sense, i.e. you can't have a negative quantity of a character\n",
    "# This changes all -1 to 0\n",
    "full_df.dtypes == 'int64'\n",
    "\n",
    "def remove_negatives(full_df):\n",
    "    full_df[full_df == -1] = 0\n",
    "remove_negatives(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dYB4m2v1Uk7i"
   },
   "outputs": [],
   "source": [
    "# unit test \n",
    "is_it_working = []\n",
    "def data_cleaning_unit_test(column):\n",
    "    did_it_work =  {'Yes':0 , 'No':0}\n",
    "    for i in column:\n",
    "        if i >= 0:\n",
    "            did_it_work['Yes'] += 1\n",
    "        elif i <0:\n",
    "            did_it_work['No'] += 1\n",
    "    if did_it_work['No'] > 0:\n",
    "        print(column.name,'=', 'Not working')\n",
    "    else:\n",
    "        print(column.name,'=', 'It worked!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gce-FFzDU9vL",
    "outputId": "b2dd8c84-660e-4cee-a0a2-5c8ea8b90586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qty_dot_url = It worked!\n",
      "qty_hyphen_url = It worked!\n",
      "qty_underline_url = It worked!\n",
      "qty_slash_url = It worked!\n",
      "qty_questionmark_url = It worked!\n",
      "qty_equal_url = It worked!\n",
      "qty_at_url = It worked!\n",
      "qty_and_url = It worked!\n",
      "qty_exclamation_url = It worked!\n",
      "qty_space_url = It worked!\n",
      "qty_tilde_url = It worked!\n",
      "qty_comma_url = It worked!\n",
      "qty_plus_url = It worked!\n",
      "qty_asterisk_url = It worked!\n",
      "qty_hashtag_url = It worked!\n",
      "qty_dollar_url = It worked!\n",
      "qty_percent_url = It worked!\n",
      "qty_tld_url = It worked!\n",
      "length_url = It worked!\n",
      "qty_dot_domain = It worked!\n",
      "qty_hyphen_domain = It worked!\n",
      "qty_underline_domain = It worked!\n",
      "qty_slash_domain = It worked!\n",
      "qty_questionmark_domain = It worked!\n",
      "qty_equal_domain = It worked!\n",
      "qty_at_domain = It worked!\n",
      "qty_and_domain = It worked!\n",
      "qty_exclamation_domain = It worked!\n",
      "qty_space_domain = It worked!\n",
      "qty_tilde_domain = It worked!\n",
      "qty_comma_domain = It worked!\n",
      "qty_plus_domain = It worked!\n",
      "qty_asterisk_domain = It worked!\n",
      "qty_hashtag_domain = It worked!\n",
      "qty_dollar_domain = It worked!\n",
      "qty_percent_domain = It worked!\n",
      "qty_vowels_domain = It worked!\n",
      "domain_length = It worked!\n",
      "domain_in_ip = It worked!\n",
      "server_client_domain = It worked!\n",
      "qty_dot_directory = It worked!\n",
      "qty_hyphen_directory = It worked!\n",
      "qty_underline_directory = It worked!\n",
      "qty_slash_directory = It worked!\n",
      "qty_questionmark_directory = It worked!\n",
      "qty_equal_directory = It worked!\n",
      "qty_at_directory = It worked!\n",
      "qty_and_directory = It worked!\n",
      "qty_exclamation_directory = It worked!\n",
      "qty_space_directory = It worked!\n",
      "qty_tilde_directory = It worked!\n",
      "qty_comma_directory = It worked!\n",
      "qty_plus_directory = It worked!\n",
      "qty_asterisk_directory = It worked!\n",
      "qty_hashtag_directory = It worked!\n",
      "qty_dollar_directory = It worked!\n",
      "qty_percent_directory = It worked!\n",
      "directory_length = It worked!\n",
      "qty_dot_file = It worked!\n",
      "qty_hyphen_file = It worked!\n",
      "qty_underline_file = It worked!\n",
      "qty_slash_file = It worked!\n",
      "qty_questionmark_file = It worked!\n",
      "qty_equal_file = It worked!\n",
      "qty_at_file = It worked!\n",
      "qty_and_file = It worked!\n",
      "qty_exclamation_file = It worked!\n",
      "qty_space_file = It worked!\n",
      "qty_tilde_file = It worked!\n",
      "qty_comma_file = It worked!\n",
      "qty_plus_file = It worked!\n",
      "qty_asterisk_file = It worked!\n",
      "qty_hashtag_file = It worked!\n",
      "qty_dollar_file = It worked!\n",
      "qty_percent_file = It worked!\n",
      "file_length = It worked!\n",
      "qty_dot_params = It worked!\n",
      "qty_hyphen_params = It worked!\n",
      "qty_underline_params = It worked!\n",
      "qty_slash_params = It worked!\n",
      "qty_questionmark_params = It worked!\n",
      "qty_equal_params = It worked!\n",
      "qty_at_params = It worked!\n",
      "qty_and_params = It worked!\n",
      "qty_exclamation_params = It worked!\n",
      "qty_space_params = It worked!\n",
      "qty_tilde_params = It worked!\n",
      "qty_comma_params = It worked!\n",
      "qty_plus_params = It worked!\n",
      "qty_asterisk_params = It worked!\n",
      "qty_hashtag_params = It worked!\n",
      "qty_dollar_params = It worked!\n",
      "qty_percent_params = It worked!\n",
      "params_length = It worked!\n",
      "tld_present_params = It worked!\n",
      "qty_params = It worked!\n",
      "email_in_url = It worked!\n",
      "time_response = It worked!\n",
      "domain_spf = It worked!\n",
      "asn_ip = It worked!\n",
      "time_domain_activation = It worked!\n",
      "time_domain_expiration = It worked!\n",
      "qty_ip_resolved = It worked!\n",
      "qty_nameservers = It worked!\n",
      "qty_mx_servers = It worked!\n",
      "ttl_hostname = It worked!\n",
      "tls_ssl_certificate = It worked!\n",
      "qty_redirects = It worked!\n",
      "url_google_index = It worked!\n",
      "domain_google_index = It worked!\n",
      "url_shortened = It worked!\n",
      "phishing = It worked!\n"
     ]
    }
   ],
   "source": [
    "for col in full_df.columns.tolist():\n",
    "    data_cleaning_unit_test(full_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUuo04VLzBkB"
   },
   "source": [
    "---\n",
    "\n",
    "# Keras Sequential NN model on entire dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "Uyt5-sN-7p1H",
    "outputId": "84d0abc1-bab5-49ae-89de-0f68874238ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>qty_space_url</th>\n",
       "      <th>...</th>\n",
       "      <th>time_domain_expiration</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.011480</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39002</th>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680199</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.662860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39668</th>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.439823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82035</th>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.579014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  \\\n",
       "5676      0.000004             0.0                0.0       0.000004   \n",
       "39002     0.000777             0.0                0.0       0.000000   \n",
       "1732      0.000092             0.0                0.0       0.000000   \n",
       "39668     0.000122             0.0                0.0       0.000000   \n",
       "82035     0.000054             0.0                0.0       0.000000   \n",
       "\n",
       "       qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  \\\n",
       "5676                    0.0            0.0         0.0          0.0   \n",
       "39002                   0.0            0.0         0.0          0.0   \n",
       "1732                    0.0            0.0         0.0          0.0   \n",
       "39668                   0.0            0.0         0.0          0.0   \n",
       "82035                   0.0            0.0         0.0          0.0   \n",
       "\n",
       "       qty_exclamation_url  qty_space_url  ...  time_domain_expiration  \\\n",
       "5676                   0.0            0.0  ...                0.000797   \n",
       "39002                  0.0            0.0  ...                0.680199   \n",
       "1732                   0.0            0.0  ...                0.016112   \n",
       "39668                  0.0            0.0  ...                0.005926   \n",
       "82035                  0.0            0.0  ...                0.007212   \n",
       "\n",
       "       qty_ip_resolved  qty_nameservers  qty_mx_servers  ttl_hostname  \\\n",
       "5676          0.000004         0.000023        0.000008      0.011480   \n",
       "39002         0.001036         0.001036        0.000518      0.064003   \n",
       "1732          0.000046         0.000092        0.000046      0.662860   \n",
       "39668         0.000061         0.000122        0.000244      0.439823   \n",
       "82035         0.000027         0.000107        0.000107      0.579014   \n",
       "\n",
       "       tls_ssl_certificate  qty_redirects  url_google_index  \\\n",
       "5676              0.000004       0.000000               0.0   \n",
       "39002             0.000259       0.000259               0.0   \n",
       "1732              0.000000       0.000000               0.0   \n",
       "39668             0.000000       0.000061               0.0   \n",
       "82035             0.000000       0.000000               0.0   \n",
       "\n",
       "       domain_google_index  url_shortened  \n",
       "5676                   0.0            0.0  \n",
       "39002                  0.0            0.0  \n",
       "1732                   0.0            0.0  \n",
       "39668                  0.0            0.0  \n",
       "82035                  0.0            0.0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = full_df.iloc[:,-1]\n",
    "\n",
    "X = full_df.iloc[:,0:111]\n",
    "\n",
    "X = tf.keras.utils.normalize(X, axis=-1, order=2)\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.25, random_state=808)\n",
    "\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8L1OV6fg7py7",
    "outputId": "c0b6f0bf-129f-49dc-d2e3-af42ab1a9986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                7168      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 111)               1887      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 111)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 112       \n",
      "=================================================================\n",
      "Total params: 20,065\n",
      "Trainable params: 20,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() #clear tensorflow backend to help with memory leakage\n",
    "\n",
    "nn_mod_1 = keras.Sequential([\n",
    "                          layers.InputLayer(input_shape=[111]),                   # first layer - input - number of columns in X\n",
    "                          layers.Dense(units=64, activation='relu'),              # second layer - first dense layer - 64 output neurons w/ rectified linear unit activation\n",
    "                          layers.Dropout(0.2),                                    # third layer - first dropout layer - drop 20% of neurons\n",
    "                          layers.Dense(units=64, activation='relu'),              # fourth layer - second dense layer - 64 output neurons w/ ReLU activation\n",
    "                          layers.Dropout(0.2),                                    # fifth layer - second dropout layer - drop 20% of neurons \n",
    "                          layers.Dense(units=50, activation='relu'),              # sixth layer -  third dense layer - 50 output neurons w/ ReLU activation\n",
    "                          layers.Dropout(0.20),                                   # seventh layer - third dropout layer - drop 20% of neurons\n",
    "                          layers.Dense(units=32, activation='relu'),              # eighth layer - fourth dense layer - 32 output neurons w/ ReLU activation \n",
    "                          layers.Dropout(0.2),                                    # ninth layer - fourth dropout layer - drop 20% of neurons\n",
    "                          layers.Dense(units=32, activation='relu'),              # tenth layer - fifth dense layer - 32 output neurons w/ ReLU activation\n",
    "                          layers.Dropout(0.2),                                    # eleventh layer - fifth dropout layer - drop 20% of neurons\n",
    "                          layers.Dense(units=16, activation='relu'),              # twelfth layer - sixth dense layer - 16 output neurons w/ ReLU activation\n",
    "                          layers.Dropout(0.40),                                   # thirteenth layer - sixth dropout layer - drop 40% of neurons\n",
    "                          layers.Dense(units=16, activation='relu'),              # fourteenth layer - seventh dense layer - 16 output neurons w/ ReLU activation\n",
    "                          layers.Dropout(0.40),                                   # fifteenth layer - seventh dropout layer - drop 40% of neurons\n",
    "                          layers.Dense(units=111, activation='relu'),             # sixteenth layer - eighth dense layer - 111 output neurons w/ ReLU activation\n",
    "                          layers.Flatten(),                                       # seventeenth layer - flatten - adds column to X for predictions to fit\n",
    "                          layers.Dense(units=1, activation='sigmoid')             # eighteenth layer - output layer - 1 output neuron w/ sigmoid activation (preds <> 0, 1)\n",
    "])\n",
    "\n",
    "nn_mod_1.compile(\n",
    "    optimizer='adam', #best optimizer for noise, easy computation\n",
    "    loss='binary_crossentropy', #crossentropy between preds and val_y; preds are between 0 & 1 so we use binary\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5), #binary accuracy between preds and val_y with 0.5 threshold\n",
    "             tf.keras.metrics.AUC(), # measuring AUC (obviously) through internal measures of TP, TN, FP, FN\n",
    "             ]\n",
    ")\n",
    "\n",
    "# early stopping callback will monitor the validation data's binary accuracy for it's maximum value\n",
    "# & 25 epochs after reaching the maximum value, the model will stop running and restore the best layer weights measured.\n",
    "# I don't actually want this to run for anywhere near 500 epochs but this gives it the flexibility to learn as long as needed\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor = 'val_binary_accuracy', mode = 'max',\n",
    "                                       patience = 25, restore_best_weights = True)\n",
    "\n",
    "# this will output a table of the layers, each layer output shape, and the parameters measured by the model\n",
    "nn_mod_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this fit method:\n",
    " - does not use the original validation split (25%) during model fitting to allow for more accurate evaluation and preditions later on\n",
    " - the 75% training split (train_X, train_y) is split 70/30 during model fitting and each epoch the 70/30 split is, well, shuffled \n",
    " - the epochs are set to 500 (500 iterations) but the early stopping callback should keep the epochs significantly less than that\n",
    " - the batch_size is how many rows are fed into the model at a time\n",
    " - there are 8 workers to *hopefully* help it run faster, in addition to the early stopping callback being applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umxFYgEP7pwr",
    "outputId": "0dddeca1-ba32-41d9-e67b-fb5578b662c0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/500\n",
      "46539/46539 [==============================] - 3s 65us/sample - loss: 0.5920 - binary_accuracy: 0.6562 - auc: 0.7048 - val_loss: 0.5604 - val_binary_accuracy: 0.7227 - val_auc: 0.7626\n",
      "Epoch 2/500\n",
      "46539/46539 [==============================] - 2s 38us/sample - loss: 0.5526 - binary_accuracy: 0.7129 - auc: 0.7529 - val_loss: 0.5767 - val_binary_accuracy: 0.7258 - val_auc: 0.7677\n",
      "Epoch 3/500\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.5400 - binary_accuracy: 0.7198 - auc: 0.7615 - val_loss: 0.5612 - val_binary_accuracy: 0.7312 - val_auc: 0.7801\n",
      "Epoch 4/500\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.5184 - binary_accuracy: 0.7337 - auc: 0.7855 - val_loss: 0.5531 - val_binary_accuracy: 0.7488 - val_auc: 0.8107\n",
      "Epoch 5/500\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.4615 - binary_accuracy: 0.7797 - auc: 0.8449 - val_loss: 0.4814 - val_binary_accuracy: 0.7957 - val_auc: 0.8849\n",
      "Epoch 6/500\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.4140 - binary_accuracy: 0.8149 - auc: 0.8878 - val_loss: 0.4270 - val_binary_accuracy: 0.8189 - val_auc: 0.9082\n",
      "Epoch 7/500\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.3821 - binary_accuracy: 0.8395 - auc: 0.9073 - val_loss: 0.3927 - val_binary_accuracy: 0.8771 - val_auc: 0.9372\n",
      "Epoch 8/500\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.3500 - binary_accuracy: 0.8607 - auc: 0.9224 - val_loss: 0.3875 - val_binary_accuracy: 0.8787 - val_auc: 0.9416\n",
      "Epoch 9/500\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.3305 - binary_accuracy: 0.8699 - auc: 0.9294 - val_loss: 0.3420 - val_binary_accuracy: 0.9016 - val_auc: 0.9518\n",
      "Epoch 10/500\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.3255 - binary_accuracy: 0.8714 - auc: 0.9300 - val_loss: 0.3810 - val_binary_accuracy: 0.8999 - val_auc: 0.9557\n",
      "Epoch 11/500\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.3131 - binary_accuracy: 0.8781 - auc: 0.9347 - val_loss: 0.3071 - val_binary_accuracy: 0.8962 - val_auc: 0.9571\n",
      "Epoch 12/500\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.3085 - binary_accuracy: 0.8789 - auc: 0.9361 - val_loss: 0.3417 - val_binary_accuracy: 0.9036 - val_auc: 0.9612\n",
      "Epoch 13/500\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2978 - binary_accuracy: 0.8834 - auc: 0.9393 - val_loss: 0.3277 - val_binary_accuracy: 0.8917 - val_auc: 0.9591\n",
      "Epoch 14/500\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2989 - binary_accuracy: 0.8801 - auc: 0.9389 - val_loss: 0.3221 - val_binary_accuracy: 0.9100 - val_auc: 0.9604\n",
      "Epoch 15/500\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2850 - binary_accuracy: 0.8873 - auc: 0.9432 - val_loss: 0.3180 - val_binary_accuracy: 0.8953 - val_auc: 0.9573\n",
      "Epoch 16/500\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2864 - binary_accuracy: 0.8865 - auc: 0.9431 - val_loss: 0.2724 - val_binary_accuracy: 0.9152 - val_auc: 0.9617\n",
      "Epoch 17/500\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.2743 - binary_accuracy: 0.8917 - auc: 0.9478 - val_loss: 0.2521 - val_binary_accuracy: 0.9153 - val_auc: 0.9621\n",
      "Epoch 18/500\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.2793 - binary_accuracy: 0.8894 - auc: 0.9448 - val_loss: 0.2660 - val_binary_accuracy: 0.9144 - val_auc: 0.9595\n",
      "Epoch 19/500\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.2724 - binary_accuracy: 0.8933 - auc: 0.9479 - val_loss: 0.3780 - val_binary_accuracy: 0.9062 - val_auc: 0.9662\n",
      "Epoch 20/500\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2772 - binary_accuracy: 0.8901 - auc: 0.9462 - val_loss: 0.2507 - val_binary_accuracy: 0.9188 - val_auc: 0.9628\n",
      "Epoch 21/500\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2699 - binary_accuracy: 0.8941 - auc: 0.9480 - val_loss: 0.2913 - val_binary_accuracy: 0.9142 - val_auc: 0.9645\n",
      "Epoch 22/500\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2730 - binary_accuracy: 0.8935 - auc: 0.9469 - val_loss: 0.2964 - val_binary_accuracy: 0.8847 - val_auc: 0.9584\n",
      "Epoch 23/500\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2701 - binary_accuracy: 0.8931 - auc: 0.9487 - val_loss: 0.3000 - val_binary_accuracy: 0.8992 - val_auc: 0.9606\n",
      "Epoch 24/500\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2749 - binary_accuracy: 0.8929 - auc: 0.9471 - val_loss: 0.2520 - val_binary_accuracy: 0.9077 - val_auc: 0.9648\n",
      "Epoch 25/500\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2641 - binary_accuracy: 0.8954 - auc: 0.9508 - val_loss: 0.2462 - val_binary_accuracy: 0.8963 - val_auc: 0.9636\n",
      "Epoch 26/500\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2713 - binary_accuracy: 0.8941 - auc: 0.9475 - val_loss: 0.2528 - val_binary_accuracy: 0.8887 - val_auc: 0.9656\n",
      "Epoch 27/500\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2682 - binary_accuracy: 0.8958 - auc: 0.9482 - val_loss: 0.2671 - val_binary_accuracy: 0.9192 - val_auc: 0.9648\n",
      "Epoch 28/500\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2573 - binary_accuracy: 0.9000 - auc: 0.9521 - val_loss: 0.3385 - val_binary_accuracy: 0.9182 - val_auc: 0.9644\n",
      "Epoch 29/500\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2536 - binary_accuracy: 0.9017 - auc: 0.9534 - val_loss: 0.2806 - val_binary_accuracy: 0.9134 - val_auc: 0.9592\n",
      "Epoch 30/500\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2569 - binary_accuracy: 0.9010 - auc: 0.9529 - val_loss: 0.2808 - val_binary_accuracy: 0.9195 - val_auc: 0.9647\n",
      "Epoch 31/500\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2585 - binary_accuracy: 0.8988 - auc: 0.9538 - val_loss: 0.2332 - val_binary_accuracy: 0.9192 - val_auc: 0.9695\n",
      "Epoch 32/500\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2538 - binary_accuracy: 0.9005 - auc: 0.9536 - val_loss: 0.3069 - val_binary_accuracy: 0.9201 - val_auc: 0.9657\n",
      "Epoch 33/500\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2499 - binary_accuracy: 0.9012 - auc: 0.9554 - val_loss: 0.2298 - val_binary_accuracy: 0.9157 - val_auc: 0.9674\n",
      "Epoch 34/500\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2572 - binary_accuracy: 0.8986 - auc: 0.9521 - val_loss: 0.3786 - val_binary_accuracy: 0.8215 - val_auc: 0.9578\n",
      "Epoch 35/500\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2534 - binary_accuracy: 0.9016 - auc: 0.9538 - val_loss: 0.2603 - val_binary_accuracy: 0.9127 - val_auc: 0.9662\n",
      "Epoch 36/500\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2466 - binary_accuracy: 0.9036 - auc: 0.9557 - val_loss: 0.4091 - val_binary_accuracy: 0.8576 - val_auc: 0.9659\n",
      "Epoch 37/500\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2510 - binary_accuracy: 0.9009 - auc: 0.9541 - val_loss: 0.2364 - val_binary_accuracy: 0.9219 - val_auc: 0.9691\n",
      "Epoch 38/500\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2491 - binary_accuracy: 0.9026 - auc: 0.9549 - val_loss: 0.2427 - val_binary_accuracy: 0.9006 - val_auc: 0.9657\n",
      "Epoch 39/500\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2511 - binary_accuracy: 0.9010 - auc: 0.9554 - val_loss: 0.2619 - val_binary_accuracy: 0.9201 - val_auc: 0.9693\n",
      "Epoch 40/500\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2490 - binary_accuracy: 0.9017 - auc: 0.9560 - val_loss: 0.2263 - val_binary_accuracy: 0.9176 - val_auc: 0.9697\n",
      "Epoch 41/500\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2493 - binary_accuracy: 0.9021 - auc: 0.9546 - val_loss: 0.2265 - val_binary_accuracy: 0.9169 - val_auc: 0.9668\n",
      "Epoch 42/500\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2506 - binary_accuracy: 0.9026 - auc: 0.9550 - val_loss: 0.2279 - val_binary_accuracy: 0.9196 - val_auc: 0.9697\n",
      "Epoch 43/500\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2518 - binary_accuracy: 0.9028 - auc: 0.9547 - val_loss: 0.3634 - val_binary_accuracy: 0.8983 - val_auc: 0.9680\n",
      "Epoch 44/500\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2438 - binary_accuracy: 0.9051 - auc: 0.9577 - val_loss: 0.2485 - val_binary_accuracy: 0.9185 - val_auc: 0.9693\n",
      "Epoch 45/500\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2487 - binary_accuracy: 0.9019 - auc: 0.9559 - val_loss: 0.2504 - val_binary_accuracy: 0.9192 - val_auc: 0.9668\n",
      "Epoch 46/500\n",
      "46539/46539 [==============================] - 3s 65us/sample - loss: 0.2450 - binary_accuracy: 0.9030 - auc: 0.9575 - val_loss: 0.2383 - val_binary_accuracy: 0.9214 - val_auc: 0.9700\n",
      "Epoch 47/500\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2529 - binary_accuracy: 0.9010 - auc: 0.9547 - val_loss: 0.2715 - val_binary_accuracy: 0.9077 - val_auc: 0.9665\n",
      "Epoch 48/500\n",
      "46539/46539 [==============================] - 3s 64us/sample - loss: 0.2427 - binary_accuracy: 0.9054 - auc: 0.9570 - val_loss: 0.2787 - val_binary_accuracy: 0.8949 - val_auc: 0.9662\n",
      "Epoch 49/500\n",
      "46539/46539 [==============================] - 3s 64us/sample - loss: 0.2438 - binary_accuracy: 0.9030 - auc: 0.9576 - val_loss: 0.2288 - val_binary_accuracy: 0.9162 - val_auc: 0.9676\n",
      "Epoch 50/500\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2447 - binary_accuracy: 0.9045 - auc: 0.9565 - val_loss: 0.4476 - val_binary_accuracy: 0.8175 - val_auc: 0.9583\n",
      "Epoch 51/500\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2468 - binary_accuracy: 0.9033 - auc: 0.9561 - val_loss: 0.2939 - val_binary_accuracy: 0.9064 - val_auc: 0.9648\n",
      "Epoch 52/500\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2399 - binary_accuracy: 0.9059 - auc: 0.9583 - val_loss: 0.2543 - val_binary_accuracy: 0.9172 - val_auc: 0.9667\n",
      "Epoch 53/500\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2471 - binary_accuracy: 0.9022 - auc: 0.9569 - val_loss: 0.2938 - val_binary_accuracy: 0.9131 - val_auc: 0.9708\n",
      "Epoch 54/500\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2386 - binary_accuracy: 0.9065 - auc: 0.9592 - val_loss: 0.2843 - val_binary_accuracy: 0.9163 - val_auc: 0.9712\n",
      "Epoch 55/500\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.2375 - binary_accuracy: 0.9061 - auc: 0.9604 - val_loss: 0.2838 - val_binary_accuracy: 0.8960 - val_auc: 0.9711\n",
      "Epoch 56/500\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2385 - binary_accuracy: 0.9062 - auc: 0.9598 - val_loss: 0.2230 - val_binary_accuracy: 0.9147 - val_auc: 0.9688\n",
      "Epoch 57/500\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2426 - binary_accuracy: 0.9041 - auc: 0.9573 - val_loss: 0.2372 - val_binary_accuracy: 0.9178 - val_auc: 0.9683\n",
      "Epoch 58/500\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2436 - binary_accuracy: 0.9061 - auc: 0.9578 - val_loss: 0.2512 - val_binary_accuracy: 0.9070 - val_auc: 0.9671\n",
      "Epoch 59/500\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2377 - binary_accuracy: 0.9076 - auc: 0.9592 - val_loss: 0.2983 - val_binary_accuracy: 0.9000 - val_auc: 0.9676\n",
      "Epoch 60/500\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2399 - binary_accuracy: 0.9047 - auc: 0.9591 - val_loss: 0.2312 - val_binary_accuracy: 0.9172 - val_auc: 0.9723\n",
      "Epoch 61/500\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2340 - binary_accuracy: 0.9083 - auc: 0.9608 - val_loss: 0.3631 - val_binary_accuracy: 0.8551 - val_auc: 0.9691\n",
      "Epoch 62/500\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2423 - binary_accuracy: 0.9043 - auc: 0.9577 - val_loss: 0.4072 - val_binary_accuracy: 0.9120 - val_auc: 0.9639\n"
     ]
    }
   ],
   "source": [
    "history1 = nn_mod_1.fit(train_X, train_y, validation_split=0.30, shuffle=True, batch_size= 175, epochs=500, callbacks = [earlystopping], workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "muIvYULG7pum",
    "outputId": "4b190e22-1084-4dac-94c5-703f3cdc87bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.288718</td>\n",
       "      <td>0.880426</td>\n",
       "      <td>0.934722</td>\n",
       "      <td>0.314397</td>\n",
       "      <td>0.889321</td>\n",
       "      <td>0.949931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.051619</td>\n",
       "      <td>0.052444</td>\n",
       "      <td>0.090034</td>\n",
       "      <td>0.049732</td>\n",
       "      <td>0.047198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.234046</td>\n",
       "      <td>0.656159</td>\n",
       "      <td>0.704803</td>\n",
       "      <td>0.222977</td>\n",
       "      <td>0.722701</td>\n",
       "      <td>0.762629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.246682</td>\n",
       "      <td>0.887815</td>\n",
       "      <td>0.943606</td>\n",
       "      <td>0.250806</td>\n",
       "      <td>0.894966</td>\n",
       "      <td>0.959140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.255353</td>\n",
       "      <td>0.900707</td>\n",
       "      <td>0.953500</td>\n",
       "      <td>0.284053</td>\n",
       "      <td>0.907676</td>\n",
       "      <td>0.964840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.283598</td>\n",
       "      <td>0.902995</td>\n",
       "      <td>0.956423</td>\n",
       "      <td>0.357818</td>\n",
       "      <td>0.917114</td>\n",
       "      <td>0.967601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.592042</td>\n",
       "      <td>0.908313</td>\n",
       "      <td>0.960792</td>\n",
       "      <td>0.576703</td>\n",
       "      <td>0.921889</td>\n",
       "      <td>0.972292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  binary_accuracy        auc   val_loss  val_binary_accuracy  \\\n",
       "count  62.000000        62.000000  62.000000  62.000000            62.000000   \n",
       "mean    0.288718         0.880426   0.934722   0.314397             0.889321   \n",
       "std     0.081481         0.051619   0.052444   0.090034             0.049732   \n",
       "min     0.234046         0.656159   0.704803   0.222977             0.722701   \n",
       "25%     0.246682         0.887815   0.943606   0.250806             0.894966   \n",
       "50%     0.255353         0.900707   0.953500   0.284053             0.907676   \n",
       "75%     0.283598         0.902995   0.956423   0.357818             0.917114   \n",
       "max     0.592042         0.908313   0.960792   0.576703             0.921889   \n",
       "\n",
       "         val_auc  \n",
       "count  62.000000  \n",
       "mean    0.949931  \n",
       "std     0.047198  \n",
       "min     0.762629  \n",
       "25%     0.959140  \n",
       "50%     0.964840  \n",
       "75%     0.967601  \n",
       "max     0.972292  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn model fit metric measures into a pandas dataframe\n",
    "\n",
    "history_df1 = pd.DataFrame(history1.history)\n",
    "\n",
    "history_df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPDWBW-zoQPA"
   },
   "source": [
    "## evaluating the model and getting the overall model metrics following model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDRvjAls7psK",
    "outputId": "23ba4ee3-323f-4d37-c95e-88e6c4d04712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66485/66485 [==============================] - 5s 73us/sample - loss: 0.2372 - binary_accuracy: 0.9216 - auc: 0.9688\n",
      "22162/22162 [==============================] - 2s 74us/sample - loss: 0.2397 - binary_accuracy: 0.9210 - auc: 0.9678\n"
     ]
    }
   ],
   "source": [
    "#tf.keras function to evaluate the model & record best metrics\n",
    "\n",
    "train_acc = nn_mod_1.evaluate(train_X, train_y)  # evaluation w/ best measures of training data -- aka model fit\n",
    "test_acc = nn_mod_1.evaluate(val_X, val_y)       # evaluation w/ best measures of validation/testing data -- the model hasn't seen this data before so super important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahig1f-Z7ppm",
    "outputId": "3e9c369b-1770-4002-f0df-fd8edc5d256f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.23967102434166437, 'binary_accuracy': 0.9209909, 'auc': 0.9677572}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display validation/testing evaluation metrics in a different way\n",
    "\n",
    "dict(zip(nn_mod_1.metrics_names, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4V9I4_yoQPB"
   },
   "source": [
    "### graphs of the training vs. validation metrics across model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "2D__R-yv7plw",
    "outputId": "1a83c4e3-9c71-4496-e880-970996150806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss (binary_crossentropy): 0.22297702362066307\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df1.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss (binary_crossentropy): {}\".format(history_df1['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "fo_odY_Z-Fc-",
    "outputId": "151dfc5a-1714-4ece-d52f-ee7aab88d502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum AUC: 0.972291886806488\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df1.loc[:, ['auc', 'val_auc']].plot();\n",
    "print(\"Maximum AUC: {}\".format(history_df1['val_auc'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "sAvi3T0k-FaZ",
    "outputId": "28854671-7e9a-47dc-c7f1-ba7259c2ecba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum validation binary accuracy: 0.9218891263008118\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df1.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();\n",
    "print(\"Maximum validation binary accuracy: {}\".format(history_df1['val_binary_accuracy'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxyK2GDAoQPC"
   },
   "source": [
    "## making probablistic predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imHHWk12-FYT",
    "outputId": "84c8eb19-a8fa-4bcd-f58e-fee4e2f70a27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9009093 ],\n",
       "       [0.01844689],\n",
       "       [0.42265916],\n",
       "       ...,\n",
       "       [0.2262679 ],\n",
       "       [0.05991422],\n",
       "       [0.9009093 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1 = nn_mod_1.predict(val_X) # this is tf.keras function & could be called on the entire dataset but it's not fair to ask the model to predict on data already seen\n",
    "preds1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi_xm1LgUlOg"
   },
   "source": [
    "---\n",
    "# NN in a more deployable format\n",
    "\n",
    "## this is the model format to be used in the .py file for deployment\n",
    "\n",
    "### this format also allows for cross-validation to validate the model's integrity/results\n",
    " - the cross-validation is the most time consuming portion of the notebook, fyi\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zJtoHaTV8Qcb"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor = 'val_acc', mode = 'max', #this needs to be changed to 'val_accuracy' if running in a colab notebook (for some reason jupyter is different)\n",
    "                                         patience = 15, restore_best_weights = True)\n",
    "\n",
    "# building the model as a callable function for easier use with the sklearn wrapper\n",
    "\n",
    "def phish_nn():\n",
    "  model = keras.Sequential()\n",
    "  model.add(tf.keras.layers.InputLayer(input_shape=[111]))\n",
    "  model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.2))\n",
    "  model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.2))\n",
    "  model.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.20))\n",
    "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.2))\n",
    "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.2))\n",
    "  model.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.40))\n",
    "  model.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.40))\n",
    "  model.add(tf.keras.layers.Dense(units=111, activation='relu'))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) #had to slightly alter these parameters per the limitations on metric measuring in the sklearn wrapper\n",
    "  model.fit(train_X, train_y, validation_split=0.30, batch_size= 175, epochs=50, callbacks = [earlystopping], workers=8) #lowered epochs b/c w/cv there will be more epochs than in the original model fitting\n",
    "  model.predict(val_X) #give the model the ability to predict as above\n",
    "  model.evaluate(val_X, val_y) #give the model the ability to evaluate like was done above\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dh4qppW9FZRj"
   },
   "outputs": [],
   "source": [
    "mod = KerasClassifier(build_fn=phish_nn,\n",
    "                        epochs=10,\n",
    "                        batch_size=175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "LONFSzATMKWZ"
   },
   "outputs": [],
   "source": [
    "num_folds=5\n",
    "kfold=StratifiedKFold(n_splits=num_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jyuAHDIMTJh",
    "outputId": "a9e35e5e-3a1c-4462-8c9f-f2d53828fd38",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.5944 - acc: 0.6553 - val_loss: 0.5813 - val_acc: 0.7160\n",
      "Epoch 2/50\n",
      "46539/46539 [==============================] - 2s 36us/sample - loss: 0.5523 - acc: 0.7117 - val_loss: 0.5753 - val_acc: 0.7259\n",
      "Epoch 3/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.5422 - acc: 0.7207 - val_loss: 0.5747 - val_acc: 0.7209\n",
      "Epoch 4/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.5223 - acc: 0.7310 - val_loss: 0.4953 - val_acc: 0.7494\n",
      "Epoch 5/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.4771 - acc: 0.7678 - val_loss: 0.4569 - val_acc: 0.7913\n",
      "Epoch 6/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.4372 - acc: 0.8020 - val_loss: 0.4805 - val_acc: 0.7789\n",
      "Epoch 7/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.4005 - acc: 0.8280 - val_loss: 0.4235 - val_acc: 0.8262\n",
      "Epoch 8/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.3639 - acc: 0.8555 - val_loss: 0.4039 - val_acc: 0.8363\n",
      "Epoch 9/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.3494 - acc: 0.8634 - val_loss: 0.3364 - val_acc: 0.8962\n",
      "Epoch 10/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.3342 - acc: 0.8695 - val_loss: 0.3284 - val_acc: 0.8975\n",
      "Epoch 11/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.3237 - acc: 0.8733 - val_loss: 0.2953 - val_acc: 0.9081\n",
      "Epoch 12/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.3231 - acc: 0.8729 - val_loss: 0.3034 - val_acc: 0.8788\n",
      "Epoch 13/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.3132 - acc: 0.8775 - val_loss: 0.3046 - val_acc: 0.8971\n",
      "Epoch 14/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.3065 - acc: 0.8796 - val_loss: 0.3377 - val_acc: 0.8995\n",
      "Epoch 15/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2979 - acc: 0.8829 - val_loss: 0.2831 - val_acc: 0.9094\n",
      "Epoch 16/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.3000 - acc: 0.8822 - val_loss: 0.2602 - val_acc: 0.9017\n",
      "Epoch 17/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2939 - acc: 0.8846 - val_loss: 0.2577 - val_acc: 0.8993\n",
      "Epoch 18/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2862 - acc: 0.8880 - val_loss: 0.2836 - val_acc: 0.9026\n",
      "Epoch 19/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2914 - acc: 0.8866 - val_loss: 0.2953 - val_acc: 0.8998\n",
      "Epoch 20/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2809 - acc: 0.8899 - val_loss: 0.2649 - val_acc: 0.9131\n",
      "Epoch 21/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2859 - acc: 0.8873 - val_loss: 0.3349 - val_acc: 0.9004\n",
      "Epoch 22/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.2737 - acc: 0.8936 - val_loss: 0.2654 - val_acc: 0.9203\n",
      "Epoch 23/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2780 - acc: 0.8909 - val_loss: 0.2530 - val_acc: 0.9092\n",
      "Epoch 24/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2815 - acc: 0.8907 - val_loss: 0.2722 - val_acc: 0.9006\n",
      "Epoch 25/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2791 - acc: 0.8901 - val_loss: 0.3760 - val_acc: 0.8827\n",
      "Epoch 26/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2769 - acc: 0.8910 - val_loss: 0.3137 - val_acc: 0.9193\n",
      "Epoch 27/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2675 - acc: 0.8952 - val_loss: 0.2842 - val_acc: 0.9063\n",
      "Epoch 28/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2750 - acc: 0.8922 - val_loss: 0.3567 - val_acc: 0.8498\n",
      "Epoch 29/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2681 - acc: 0.8952 - val_loss: 0.2434 - val_acc: 0.8977\n",
      "Epoch 30/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2680 - acc: 0.8934 - val_loss: 0.2294 - val_acc: 0.9169\n",
      "Epoch 31/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2672 - acc: 0.8955 - val_loss: 0.2453 - val_acc: 0.9166\n",
      "Epoch 32/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2725 - acc: 0.8938 - val_loss: 0.2389 - val_acc: 0.9157\n",
      "Epoch 33/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2719 - acc: 0.8920 - val_loss: 0.2977 - val_acc: 0.9073\n",
      "Epoch 34/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2652 - acc: 0.8955 - val_loss: 0.2491 - val_acc: 0.9160\n",
      "Epoch 35/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2652 - acc: 0.8955 - val_loss: 0.2889 - val_acc: 0.9162\n",
      "Epoch 36/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2728 - acc: 0.8928 - val_loss: 0.2895 - val_acc: 0.9179\n",
      "Epoch 37/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2644 - acc: 0.8963 - val_loss: 0.2705 - val_acc: 0.9065\n",
      "22162/22162 [==============================] - 1s 62us/sample - loss: 0.2685 - acc: 0.9179\n",
      "Epoch 1/10\n",
      "70917/70917 [==============================] - 3s 41us/sample - loss: 0.2781 - acc: 0.8919\n",
      "Epoch 2/10\n",
      "70917/70917 [==============================] - 3s 41us/sample - loss: 0.2717 - acc: 0.8943\n",
      "Epoch 3/10\n",
      "70917/70917 [==============================] - 3s 41us/sample - loss: 0.2723 - acc: 0.8944\n",
      "Epoch 4/10\n",
      "70917/70917 [==============================] - 3s 39us/sample - loss: 0.2650 - acc: 0.8974\n",
      "Epoch 5/10\n",
      "70917/70917 [==============================] - 3s 38us/sample - loss: 0.2666 - acc: 0.8954\n",
      "Epoch 6/10\n",
      "70917/70917 [==============================] - 3s 40us/sample - loss: 0.2619 - acc: 0.8982\n",
      "Epoch 7/10\n",
      "70917/70917 [==============================] - 3s 40us/sample - loss: 0.2651 - acc: 0.8975\n",
      "Epoch 8/10\n",
      "70917/70917 [==============================] - 3s 37us/sample - loss: 0.2688 - acc: 0.8941\n",
      "Epoch 9/10\n",
      "70917/70917 [==============================] - 3s 39us/sample - loss: 0.2646 - acc: 0.8975\n",
      "Epoch 10/10\n",
      "70917/70917 [==============================] - 3s 37us/sample - loss: 0.2582 - acc: 0.8999\n",
      "17730/17730 [==============================] - 0s 11us/sample - loss: 0.3008 - acc: 0.8869\n",
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.5950 - acc: 0.6589 - val_loss: 0.5761 - val_acc: 0.7201\n",
      "Epoch 2/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.5526 - acc: 0.7133 - val_loss: 0.5557 - val_acc: 0.7289\n",
      "Epoch 3/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.5393 - acc: 0.7227 - val_loss: 0.5595 - val_acc: 0.7308\n",
      "Epoch 4/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.5212 - acc: 0.7328 - val_loss: 0.5127 - val_acc: 0.7657\n",
      "Epoch 5/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.4694 - acc: 0.7715 - val_loss: 0.5145 - val_acc: 0.7381\n",
      "Epoch 6/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.4222 - acc: 0.8077 - val_loss: 0.4344 - val_acc: 0.8560\n",
      "Epoch 7/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.3807 - acc: 0.8427 - val_loss: 0.4341 - val_acc: 0.8184\n",
      "Epoch 8/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.3536 - acc: 0.8590 - val_loss: 0.3690 - val_acc: 0.9044\n",
      "Epoch 9/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.3391 - acc: 0.8672 - val_loss: 0.3460 - val_acc: 0.8862\n",
      "Epoch 10/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.3189 - acc: 0.8745 - val_loss: 0.3139 - val_acc: 0.8946\n",
      "Epoch 11/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.3082 - acc: 0.8800 - val_loss: 0.3021 - val_acc: 0.8948\n",
      "Epoch 12/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.2977 - acc: 0.8832 - val_loss: 0.3057 - val_acc: 0.8982\n",
      "Epoch 13/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2932 - acc: 0.8836 - val_loss: 0.2692 - val_acc: 0.9092\n",
      "Epoch 14/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2890 - acc: 0.8858 - val_loss: 0.3165 - val_acc: 0.9035\n",
      "Epoch 15/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2893 - acc: 0.8855 - val_loss: 0.3025 - val_acc: 0.9070\n",
      "Epoch 16/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2815 - acc: 0.8888 - val_loss: 0.2582 - val_acc: 0.9200\n",
      "Epoch 17/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2800 - acc: 0.8856 - val_loss: 0.2616 - val_acc: 0.9140\n",
      "Epoch 18/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2732 - acc: 0.8913 - val_loss: 0.2641 - val_acc: 0.9130\n",
      "Epoch 19/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2755 - acc: 0.8908 - val_loss: 0.2523 - val_acc: 0.9142\n",
      "Epoch 20/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2698 - acc: 0.8935 - val_loss: 0.3035 - val_acc: 0.9043\n",
      "Epoch 21/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2657 - acc: 0.8944 - val_loss: 0.2589 - val_acc: 0.9143\n",
      "Epoch 22/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2700 - acc: 0.8923 - val_loss: 0.3015 - val_acc: 0.9142\n",
      "Epoch 23/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2599 - acc: 0.8988 - val_loss: 0.2496 - val_acc: 0.8993\n",
      "Epoch 24/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2598 - acc: 0.8979 - val_loss: 0.2549 - val_acc: 0.9194\n",
      "Epoch 25/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2614 - acc: 0.8953 - val_loss: 0.3384 - val_acc: 0.8868\n",
      "Epoch 26/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2620 - acc: 0.8969 - val_loss: 0.2899 - val_acc: 0.9192\n",
      "Epoch 27/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2555 - acc: 0.9003 - val_loss: 0.2314 - val_acc: 0.9150\n",
      "Epoch 28/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2632 - acc: 0.8944 - val_loss: 0.2658 - val_acc: 0.9173\n",
      "Epoch 29/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2524 - acc: 0.9018 - val_loss: 0.2709 - val_acc: 0.9124\n",
      "Epoch 30/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2537 - acc: 0.9001 - val_loss: 0.3254 - val_acc: 0.9175\n",
      "Epoch 31/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.2537 - acc: 0.9000 - val_loss: 0.2283 - val_acc: 0.9051\n",
      "22162/22162 [==============================] - 2s 73us/sample - loss: 0.2622 - acc: 0.9153\n",
      "Epoch 1/10\n",
      "70917/70917 [==============================] - 4s 49us/sample - loss: 0.2731 - acc: 0.8935\n",
      "Epoch 2/10\n",
      "70917/70917 [==============================] - 3s 45us/sample - loss: 0.2726 - acc: 0.8922\n",
      "Epoch 3/10\n",
      "70917/70917 [==============================] - 3s 47us/sample - loss: 0.2652 - acc: 0.8953\n",
      "Epoch 4/10\n",
      "70917/70917 [==============================] - 3s 45us/sample - loss: 0.2699 - acc: 0.8928\n",
      "Epoch 5/10\n",
      "70917/70917 [==============================] - 3s 45us/sample - loss: 0.2639 - acc: 0.8972\n",
      "Epoch 6/10\n",
      "70917/70917 [==============================] - 3s 45us/sample - loss: 0.2548 - acc: 0.9007\n",
      "Epoch 7/10\n",
      "70917/70917 [==============================] - 3s 44us/sample - loss: 0.2542 - acc: 0.9009\n",
      "Epoch 8/10\n",
      "70917/70917 [==============================] - 3s 44us/sample - loss: 0.2569 - acc: 0.8990\n",
      "Epoch 9/10\n",
      "70917/70917 [==============================] - 3s 44us/sample - loss: 0.2604 - acc: 0.8968\n",
      "Epoch 10/10\n",
      "70917/70917 [==============================] - 3s 44us/sample - loss: 0.2498 - acc: 0.9013\n",
      "17730/17730 [==============================] - 0s 14us/sample - loss: 0.2356 - acc: 0.9105\n",
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.5905 - acc: 0.6581 - val_loss: 0.5705 - val_acc: 0.7207\n",
      "Epoch 2/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.5505 - acc: 0.7146 - val_loss: 0.5696 - val_acc: 0.7269\n",
      "Epoch 3/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.5394 - acc: 0.7213 - val_loss: 0.5515 - val_acc: 0.7347\n",
      "Epoch 4/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.5097 - acc: 0.7438 - val_loss: 0.4865 - val_acc: 0.7772\n",
      "Epoch 5/50\n",
      "46539/46539 [==============================] - 2s 40us/sample - loss: 0.4634 - acc: 0.7790 - val_loss: 0.4558 - val_acc: 0.8255\n",
      "Epoch 6/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.4150 - acc: 0.8154 - val_loss: 0.3832 - val_acc: 0.8566\n",
      "Epoch 7/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.3804 - acc: 0.8455 - val_loss: 0.3594 - val_acc: 0.8871\n",
      "Epoch 8/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.3549 - acc: 0.8605 - val_loss: 0.4627 - val_acc: 0.8807\n",
      "Epoch 9/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.3283 - acc: 0.8732 - val_loss: 0.3604 - val_acc: 0.8862\n",
      "Epoch 10/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.3204 - acc: 0.8743 - val_loss: 0.3141 - val_acc: 0.8695\n",
      "Epoch 11/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.3142 - acc: 0.8791 - val_loss: 0.3348 - val_acc: 0.9059\n",
      "Epoch 12/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.3037 - acc: 0.8800 - val_loss: 0.3687 - val_acc: 0.8342\n",
      "Epoch 13/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.3036 - acc: 0.8812 - val_loss: 0.3071 - val_acc: 0.8949\n",
      "Epoch 14/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2922 - acc: 0.8842 - val_loss: 0.3385 - val_acc: 0.8881\n",
      "Epoch 15/50\n",
      "46539/46539 [==============================] - 2s 54us/sample - loss: 0.2904 - acc: 0.8862 - val_loss: 0.3105 - val_acc: 0.8954\n",
      "Epoch 16/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.2841 - acc: 0.8880 - val_loss: 0.3088 - val_acc: 0.9088\n",
      "Epoch 17/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2818 - acc: 0.8895 - val_loss: 0.2705 - val_acc: 0.9111\n",
      "Epoch 18/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2817 - acc: 0.8878 - val_loss: 0.3552 - val_acc: 0.9045\n",
      "Epoch 19/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2917 - acc: 0.8822 - val_loss: 0.2648 - val_acc: 0.9129\n",
      "Epoch 20/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2829 - acc: 0.8892 - val_loss: 0.2761 - val_acc: 0.9142\n",
      "Epoch 21/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2713 - acc: 0.8942 - val_loss: 0.2912 - val_acc: 0.9073\n",
      "Epoch 22/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2695 - acc: 0.8943 - val_loss: 0.2689 - val_acc: 0.9071\n",
      "Epoch 23/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2707 - acc: 0.8944 - val_loss: 0.3482 - val_acc: 0.9026\n",
      "Epoch 24/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2618 - acc: 0.8963 - val_loss: 0.3099 - val_acc: 0.9125\n",
      "Epoch 25/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2637 - acc: 0.8946 - val_loss: 0.2823 - val_acc: 0.9079\n",
      "Epoch 26/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2606 - acc: 0.8966 - val_loss: 0.2830 - val_acc: 0.9100\n",
      "Epoch 27/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2572 - acc: 0.8984 - val_loss: 0.3099 - val_acc: 0.9156\n",
      "Epoch 28/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2618 - acc: 0.8956 - val_loss: 0.2598 - val_acc: 0.9098\n",
      "Epoch 29/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2610 - acc: 0.8963 - val_loss: 0.2532 - val_acc: 0.8981\n",
      "Epoch 30/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2601 - acc: 0.8951 - val_loss: 0.3079 - val_acc: 0.9172\n",
      "Epoch 31/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2575 - acc: 0.9000 - val_loss: 0.2700 - val_acc: 0.9060\n",
      "Epoch 32/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.2554 - acc: 0.8981 - val_loss: 0.2641 - val_acc: 0.9159\n",
      "Epoch 33/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2531 - acc: 0.9000 - val_loss: 0.2700 - val_acc: 0.9127\n",
      "Epoch 34/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2631 - acc: 0.8946 - val_loss: 0.2681 - val_acc: 0.9166\n",
      "Epoch 35/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.2549 - acc: 0.8973 - val_loss: 0.2506 - val_acc: 0.9152\n",
      "Epoch 36/50\n",
      "46539/46539 [==============================] - 2s 40us/sample - loss: 0.2466 - acc: 0.9034 - val_loss: 0.2201 - val_acc: 0.9155\n",
      "Epoch 37/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2468 - acc: 0.9038 - val_loss: 0.2463 - val_acc: 0.9145\n",
      "Epoch 38/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2457 - acc: 0.9031 - val_loss: 0.2356 - val_acc: 0.9168\n",
      "Epoch 39/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2463 - acc: 0.9029 - val_loss: 0.2778 - val_acc: 0.9102\n",
      "Epoch 40/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2462 - acc: 0.9032 - val_loss: 0.2704 - val_acc: 0.8986\n",
      "Epoch 41/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2503 - acc: 0.9006 - val_loss: 0.2846 - val_acc: 0.9156\n",
      "Epoch 42/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2445 - acc: 0.9041 - val_loss: 0.2222 - val_acc: 0.9125\n",
      "Epoch 43/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2415 - acc: 0.9038 - val_loss: 0.2512 - val_acc: 0.9208\n",
      "Epoch 44/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2413 - acc: 0.9043 - val_loss: 0.2353 - val_acc: 0.9186\n",
      "Epoch 45/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2518 - acc: 0.8997 - val_loss: 0.3053 - val_acc: 0.8978\n",
      "Epoch 46/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.2420 - acc: 0.9054 - val_loss: 0.3284 - val_acc: 0.9092\n",
      "Epoch 47/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.2441 - acc: 0.9035 - val_loss: 0.2330 - val_acc: 0.9158\n",
      "Epoch 48/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2398 - acc: 0.9061 - val_loss: 0.2805 - val_acc: 0.9177\n",
      "Epoch 49/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2438 - acc: 0.9030 - val_loss: 0.2993 - val_acc: 0.9139\n",
      "Epoch 50/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2464 - acc: 0.9003 - val_loss: 0.2263 - val_acc: 0.9177\n",
      "22162/22162 [==============================] - 1s 65us/sample - loss: 0.2297 - acc: 0.9147\n",
      "Epoch 1/10\n",
      "70918/70918 [==============================] - 3s 43us/sample - loss: 0.2424 - acc: 0.9036\n",
      "Epoch 2/10\n",
      "70918/70918 [==============================] - 3s 38us/sample - loss: 0.2378 - acc: 0.9062\n",
      "Epoch 3/10\n",
      "70918/70918 [==============================] - 3s 41us/sample - loss: 0.2394 - acc: 0.9054\n",
      "Epoch 4/10\n",
      "70918/70918 [==============================] - 3s 42us/sample - loss: 0.2416 - acc: 0.9055\n",
      "Epoch 5/10\n",
      "70918/70918 [==============================] - 3s 43us/sample - loss: 0.2364 - acc: 0.9063\n",
      "Epoch 6/10\n",
      "70918/70918 [==============================] - 3s 42us/sample - loss: 0.2379 - acc: 0.9073\n",
      "Epoch 7/10\n",
      "70918/70918 [==============================] - 3s 42us/sample - loss: 0.2366 - acc: 0.9066\n",
      "Epoch 8/10\n",
      "70918/70918 [==============================] - 3s 41us/sample - loss: 0.2343 - acc: 0.9074\n",
      "Epoch 9/10\n",
      "70918/70918 [==============================] - 3s 37us/sample - loss: 0.2379 - acc: 0.9064\n",
      "Epoch 10/10\n",
      "70918/70918 [==============================] - 3s 38us/sample - loss: 0.2389 - acc: 0.9038\n",
      "17729/17729 [==============================] - 0s 13us/sample - loss: 0.2311 - acc: 0.9162\n",
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.6027 - acc: 0.6494 - val_loss: 0.5536 - val_acc: 0.7140\n",
      "Epoch 2/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.5535 - acc: 0.7069 - val_loss: 0.5573 - val_acc: 0.7250\n",
      "Epoch 3/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.5421 - acc: 0.7188 - val_loss: 0.5548 - val_acc: 0.7297\n",
      "Epoch 4/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.5349 - acc: 0.7230 - val_loss: 0.5346 - val_acc: 0.7379\n",
      "Epoch 5/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.5087 - acc: 0.7386 - val_loss: 0.4882 - val_acc: 0.7633\n",
      "Epoch 6/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.4618 - acc: 0.7761 - val_loss: 0.4741 - val_acc: 0.7850 0s - loss: 0.4677 \n",
      "Epoch 7/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.4376 - acc: 0.7943 - val_loss: 0.4309 - val_acc: 0.7950\n",
      "Epoch 8/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.3915 - acc: 0.8362 - val_loss: 0.4171 - val_acc: 0.8624\n",
      "Epoch 9/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.3675 - acc: 0.8523 - val_loss: 0.3901 - val_acc: 0.8807\n",
      "Epoch 10/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.3519 - acc: 0.8591 - val_loss: 0.4280 - val_acc: 0.8797\n",
      "Epoch 11/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.3320 - acc: 0.8680 - val_loss: 0.3111 - val_acc: 0.9041\n",
      "Epoch 12/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.3195 - acc: 0.8726 - val_loss: 0.3123 - val_acc: 0.8945\n",
      "Epoch 13/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.3091 - acc: 0.8787 - val_loss: 0.3266 - val_acc: 0.9060\n",
      "Epoch 14/50\n",
      "46539/46539 [==============================] - 2s 40us/sample - loss: 0.2962 - acc: 0.8837 - val_loss: 0.2872 - val_acc: 0.9012\n",
      "Epoch 15/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.3019 - acc: 0.8799 - val_loss: 0.2914 - val_acc: 0.8997\n",
      "Epoch 16/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.3005 - acc: 0.8807 - val_loss: 0.3423 - val_acc: 0.8890\n",
      "Epoch 17/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2875 - acc: 0.8865 - val_loss: 0.3050 - val_acc: 0.9160\n",
      "Epoch 18/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2846 - acc: 0.8887 - val_loss: 0.2797 - val_acc: 0.8951\n",
      "Epoch 19/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2800 - acc: 0.8905 - val_loss: 0.3158 - val_acc: 0.9008\n",
      "Epoch 20/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2722 - acc: 0.8915 - val_loss: 0.2396 - val_acc: 0.9029\n",
      "Epoch 21/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2751 - acc: 0.8925 - val_loss: 0.2588 - val_acc: 0.9119\n",
      "Epoch 22/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2675 - acc: 0.8955 - val_loss: 0.3136 - val_acc: 0.9145\n",
      "Epoch 23/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2729 - acc: 0.8933 - val_loss: 0.2497 - val_acc: 0.9166\n",
      "Epoch 24/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.2812 - acc: 0.8891 - val_loss: 0.3040 - val_acc: 0.9080\n",
      "Epoch 25/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2726 - acc: 0.8924 - val_loss: 0.2980 - val_acc: 0.9025\n",
      "Epoch 26/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2618 - acc: 0.8976 - val_loss: 0.2507 - val_acc: 0.9168\n",
      "Epoch 27/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2642 - acc: 0.8956 - val_loss: 0.2619 - val_acc: 0.9211\n",
      "Epoch 28/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2689 - acc: 0.8930 - val_loss: 0.2458 - val_acc: 0.9073\n",
      "Epoch 29/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2530 - acc: 0.9009 - val_loss: 0.2541 - val_acc: 0.9195\n",
      "Epoch 30/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2548 - acc: 0.9005 - val_loss: 0.2404 - val_acc: 0.9194\n",
      "Epoch 31/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2565 - acc: 0.8995 - val_loss: 0.3084 - val_acc: 0.9184\n",
      "Epoch 32/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2510 - acc: 0.9012 - val_loss: 0.2545 - val_acc: 0.9097\n",
      "Epoch 33/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.2539 - acc: 0.8986 - val_loss: 0.2607 - val_acc: 0.9174\n",
      "Epoch 34/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2548 - acc: 0.8995 - val_loss: 0.3957 - val_acc: 0.8724\n",
      "Epoch 35/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2581 - acc: 0.8981 - val_loss: 0.2580 - val_acc: 0.9036\n",
      "Epoch 36/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2509 - acc: 0.9007 - val_loss: 0.3205 - val_acc: 0.9192\n",
      "Epoch 37/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2544 - acc: 0.8995 - val_loss: 0.2538 - val_acc: 0.9026\n",
      "Epoch 38/50\n",
      "46539/46539 [==============================] - 2s 40us/sample - loss: 0.2542 - acc: 0.8980 - val_loss: 0.2750 - val_acc: 0.9089\n",
      "Epoch 39/50\n",
      "46539/46539 [==============================] - 2s 40us/sample - loss: 0.2468 - acc: 0.9047 - val_loss: 0.2281 - val_acc: 0.9210\n",
      "Epoch 40/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2435 - acc: 0.9061 - val_loss: 0.2458 - val_acc: 0.9227\n",
      "Epoch 41/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2467 - acc: 0.9039 - val_loss: 0.2593 - val_acc: 0.9144\n",
      "Epoch 42/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2488 - acc: 0.9025 - val_loss: 0.2324 - val_acc: 0.9196\n",
      "Epoch 43/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2440 - acc: 0.9037 - val_loss: 0.2569 - val_acc: 0.9163\n",
      "Epoch 44/50\n",
      "46539/46539 [==============================] - 2s 54us/sample - loss: 0.2418 - acc: 0.9043 - val_loss: 0.2664 - val_acc: 0.9126\n",
      "Epoch 45/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2455 - acc: 0.9041 - val_loss: 0.2437 - val_acc: 0.9194\n",
      "Epoch 46/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2396 - acc: 0.9064 - val_loss: 0.2415 - val_acc: 0.9221\n",
      "Epoch 47/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2407 - acc: 0.9061 - val_loss: 0.2398 - val_acc: 0.9182\n",
      "Epoch 48/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2479 - acc: 0.9028 - val_loss: 0.2266 - val_acc: 0.9172\n",
      "Epoch 49/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2432 - acc: 0.9058 - val_loss: 0.3072 - val_acc: 0.8889\n",
      "Epoch 50/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2442 - acc: 0.9038 - val_loss: 0.2511 - val_acc: 0.9230\n",
      "22162/22162 [==============================] - 1s 58us/sample - loss: 0.2540 - acc: 0.9219\n",
      "Epoch 1/10\n",
      "70918/70918 [==============================] - 3s 38us/sample - loss: 0.2417 - acc: 0.9056\n",
      "Epoch 2/10\n",
      "70918/70918 [==============================] - 3s 40us/sample - loss: 0.2380 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "70918/70918 [==============================] - 3s 42us/sample - loss: 0.2379 - acc: 0.9080\n",
      "Epoch 4/10\n",
      "70918/70918 [==============================] - 3s 37us/sample - loss: 0.2357 - acc: 0.9078\n",
      "Epoch 5/10\n",
      "70918/70918 [==============================] - 3s 40us/sample - loss: 0.2378 - acc: 0.9079\n",
      "Epoch 6/10\n",
      "70918/70918 [==============================] - 3s 37us/sample - loss: 0.2348 - acc: 0.9086\n",
      "Epoch 7/10\n",
      "70918/70918 [==============================] - 3s 40us/sample - loss: 0.2360 - acc: 0.9076\n",
      "Epoch 8/10\n",
      "70918/70918 [==============================] - 3s 41us/sample - loss: 0.2353 - acc: 0.9089\n",
      "Epoch 9/10\n",
      "70918/70918 [==============================] - 3s 41us/sample - loss: 0.2361 - acc: 0.9087\n",
      "Epoch 10/10\n",
      "70918/70918 [==============================] - 3s 42us/sample - loss: 0.2333 - acc: 0.9089\n",
      "17729/17729 [==============================] - 0s 12us/sample - loss: 0.2438 - acc: 0.9215\n",
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.5908 - acc: 0.6610 - val_loss: 0.5748 - val_acc: 0.7221\n",
      "Epoch 2/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.5511 - acc: 0.7142 - val_loss: 0.5661 - val_acc: 0.7218\n",
      "Epoch 3/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.5430 - acc: 0.7181 - val_loss: 0.5641 - val_acc: 0.7293\n",
      "Epoch 4/50\n",
      "46539/46539 [==============================] - 3s 66us/sample - loss: 0.5301 - acc: 0.7250 - val_loss: 0.5313 - val_acc: 0.7443\n",
      "Epoch 5/50\n",
      "46539/46539 [==============================] - 2s 54us/sample - loss: 0.4990 - acc: 0.7516 - val_loss: 0.5189 - val_acc: 0.7650\n",
      "Epoch 6/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.4464 - acc: 0.7871 - val_loss: 0.4555 - val_acc: 0.8034\n",
      "Epoch 7/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.4014 - acc: 0.8246 - val_loss: 0.4158 - val_acc: 0.8464\n",
      "Epoch 8/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.3756 - acc: 0.8428 - val_loss: 0.3534 - val_acc: 0.8749\n",
      "Epoch 9/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.3421 - acc: 0.8646 - val_loss: 0.4917 - val_acc: 0.8827\n",
      "Epoch 10/50\n",
      "46539/46539 [==============================] - 3s 66us/sample - loss: 0.3302 - acc: 0.8681 - val_loss: 0.3195 - val_acc: 0.8863\n",
      "Epoch 11/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.3139 - acc: 0.8757 - val_loss: 0.3471 - val_acc: 0.8933\n",
      "Epoch 12/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.3100 - acc: 0.8773 - val_loss: 0.3138 - val_acc: 0.8987\n",
      "Epoch 13/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.3035 - acc: 0.8810 - val_loss: 0.3152 - val_acc: 0.9075\n",
      "Epoch 14/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2912 - acc: 0.8847 - val_loss: 0.3406 - val_acc: 0.9051\n",
      "Epoch 15/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2892 - acc: 0.8853 - val_loss: 0.4454 - val_acc: 0.8245\n",
      "Epoch 16/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2816 - acc: 0.8879 - val_loss: 0.2979 - val_acc: 0.8982\n",
      "Epoch 17/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2811 - acc: 0.8882 - val_loss: 0.3307 - val_acc: 0.9022\n",
      "Epoch 18/50\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.2847 - acc: 0.8873 - val_loss: 0.3918 - val_acc: 0.8940\n",
      "Epoch 19/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2708 - acc: 0.8925 - val_loss: 0.2835 - val_acc: 0.9077\n",
      "Epoch 20/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2722 - acc: 0.8911 - val_loss: 0.3558 - val_acc: 0.9001\n",
      "Epoch 21/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2671 - acc: 0.8934 - val_loss: 0.2385 - val_acc: 0.9149\n",
      "Epoch 22/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2686 - acc: 0.8922 - val_loss: 0.3079 - val_acc: 0.9050\n",
      "Epoch 23/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2726 - acc: 0.8924 - val_loss: 0.3116 - val_acc: 0.9079\n",
      "Epoch 24/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2651 - acc: 0.8947 - val_loss: 0.3156 - val_acc: 0.9129\n",
      "Epoch 25/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2611 - acc: 0.8981 - val_loss: 0.3020 - val_acc: 0.9145\n",
      "Epoch 26/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2580 - acc: 0.8973 - val_loss: 0.3319 - val_acc: 0.9012\n",
      "Epoch 27/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2547 - acc: 0.8997 - val_loss: 0.3470 - val_acc: 0.8911\n",
      "Epoch 28/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2560 - acc: 0.8989 - val_loss: 0.2958 - val_acc: 0.9061\n",
      "Epoch 29/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2544 - acc: 0.8998 - val_loss: 0.2499 - val_acc: 0.9105\n",
      "Epoch 30/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.2573 - acc: 0.8996 - val_loss: 0.2618 - val_acc: 0.9137\n",
      "Epoch 31/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2553 - acc: 0.8986 - val_loss: 0.5488 - val_acc: 0.8963\n",
      "Epoch 32/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.2567 - acc: 0.8995 - val_loss: 0.2627 - val_acc: 0.9162\n",
      "Epoch 33/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2492 - acc: 0.9024 - val_loss: 0.3034 - val_acc: 0.9064\n",
      "Epoch 34/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2562 - acc: 0.8975 - val_loss: 0.2701 - val_acc: 0.9144\n",
      "Epoch 35/50\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.2527 - acc: 0.9004 - val_loss: 0.2585 - val_acc: 0.9178\n",
      "Epoch 36/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.2482 - acc: 0.9036 - val_loss: 0.3574 - val_acc: 0.8625\n",
      "Epoch 37/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2526 - acc: 0.9020 - val_loss: 0.2684 - val_acc: 0.9166\n",
      "Epoch 38/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2439 - acc: 0.9052 - val_loss: 0.2780 - val_acc: 0.9166\n",
      "Epoch 39/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.2543 - acc: 0.8975 - val_loss: 0.2811 - val_acc: 0.9068\n",
      "Epoch 40/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.2524 - acc: 0.9018 - val_loss: 0.2747 - val_acc: 0.9138\n",
      "Epoch 41/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.2528 - acc: 0.9007 - val_loss: 0.3535 - val_acc: 0.8819\n",
      "Epoch 42/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2457 - acc: 0.9030 - val_loss: 0.2550 - val_acc: 0.9187\n",
      "Epoch 43/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2428 - acc: 0.9044 - val_loss: 0.2971 - val_acc: 0.9099\n",
      "Epoch 44/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2471 - acc: 0.9041 - val_loss: 0.2468 - val_acc: 0.9210\n",
      "Epoch 45/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2438 - acc: 0.9050 - val_loss: 0.2900 - val_acc: 0.9110\n",
      "Epoch 46/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2455 - acc: 0.9044 - val_loss: 0.2548 - val_acc: 0.9161\n",
      "Epoch 47/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2453 - acc: 0.9044 - val_loss: 0.2971 - val_acc: 0.8830\n",
      "Epoch 48/50\n",
      "46539/46539 [==============================] - 2s 41us/sample - loss: 0.2428 - acc: 0.9056 - val_loss: 0.3924 - val_acc: 0.9059\n",
      "Epoch 49/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2485 - acc: 0.9029 - val_loss: 0.2606 - val_acc: 0.9169\n",
      "Epoch 50/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2438 - acc: 0.9042 - val_loss: 0.2460 - val_acc: 0.9188\n",
      "22162/22162 [==============================] - 1s 66us/sample - loss: 0.2486 - acc: 0.9161\n",
      "Epoch 1/10\n",
      "70918/70918 [==============================] - 3s 44us/sample - loss: 0.2446 - acc: 0.9028\n",
      "Epoch 2/10\n",
      "70918/70918 [==============================] - 4s 51us/sample - loss: 0.2457 - acc: 0.9049\n",
      "Epoch 3/10\n",
      "70918/70918 [==============================] - 3s 46us/sample - loss: 0.2419 - acc: 0.9065\n",
      "Epoch 4/10\n",
      "70918/70918 [==============================] - 3s 42us/sample - loss: 0.2379 - acc: 0.9077\n",
      "Epoch 5/10\n",
      "70918/70918 [==============================] - 3s 40us/sample - loss: 0.2382 - acc: 0.9066\n",
      "Epoch 6/10\n",
      "70918/70918 [==============================] - 3s 42us/sample - loss: 0.2417 - acc: 0.9056\n",
      "Epoch 7/10\n",
      "70918/70918 [==============================] - 3s 37us/sample - loss: 0.2363 - acc: 0.9071\n",
      "Epoch 8/10\n",
      "70918/70918 [==============================] - 3s 37us/sample - loss: 0.2421 - acc: 0.9057\n",
      "Epoch 9/10\n",
      "70918/70918 [==============================] - 3s 37us/sample - loss: 0.2337 - acc: 0.9086\n",
      "Epoch 10/10\n",
      "70918/70918 [==============================] - 3s 37us/sample - loss: 0.2368 - acc: 0.90690s - loss: 0.2362 - ac\n",
      "17729/17729 [==============================] - 0s 12us/sample - loss: 0.2423 - acc: 0.9202\n"
     ]
    }
   ],
   "source": [
    "cv_results=cross_val_score(mod,\n",
    "                           X, y,\n",
    "                           cv=kfold\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nph21h-MX-QH",
    "outputId": "d6712a67-00e5-4793-ac89-12d40cf18a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average cross-validation accuracy is:  91.11 %\n"
     ]
    }
   ],
   "source": [
    "print('The average cross-validation accuracy is: ', round(cv_results.mean(), 4)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9L6liyFVX-OA",
    "outputId": "5afb27d7-f454-475e-c667-e86d2d4198df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation for the cross-validation accuracy measure is:  0.0127 %\n"
     ]
    }
   ],
   "source": [
    "print('The standard deviation for the cross-validation accuracy measure is: ', round(cv_results.std(), 4), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNFGaP_0X-LI",
    "outputId": "bead75dd-a2e0-420f-fc0a-c56df244c6c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The five cross-validation accuracy results are: \n",
      " [0.8868584  0.91054708 0.9162389  0.92154098 0.92018723]\n"
     ]
    }
   ],
   "source": [
    "print('The five cross-validation accuracy results are: \\n', cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixiNIoMRX-Ir",
    "outputId": "b7ae55ae-938b-4b2c-e479-6476c0c28e89",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.5911 - acc: 0.6554 - val_loss: 0.5523 - val_acc: 0.6592\n",
      "Epoch 2/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.5507 - acc: 0.7119 - val_loss: 0.5629 - val_acc: 0.7271\n",
      "Epoch 3/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.5380 - acc: 0.7231 - val_loss: 0.5376 - val_acc: 0.7348\n",
      "Epoch 4/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.5163 - acc: 0.7359 - val_loss: 0.5094 - val_acc: 0.7639\n",
      "Epoch 5/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.4706 - acc: 0.7731 - val_loss: 0.4552 - val_acc: 0.7900\n",
      "Epoch 6/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.4275 - acc: 0.8075 - val_loss: 0.4188 - val_acc: 0.8494\n",
      "Epoch 7/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.3935 - acc: 0.8313 - val_loss: 0.3858 - val_acc: 0.8706\n",
      "Epoch 8/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.3642 - acc: 0.8530 - val_loss: 0.3317 - val_acc: 0.8812\n",
      "Epoch 9/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.3345 - acc: 0.8718 - val_loss: 0.3659 - val_acc: 0.8964\n",
      "Epoch 10/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.3252 - acc: 0.8732 - val_loss: 0.3469 - val_acc: 0.8913\n",
      "Epoch 11/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.3173 - acc: 0.8746 - val_loss: 0.2988 - val_acc: 0.8788\n",
      "Epoch 12/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.3148 - acc: 0.8748 - val_loss: 0.3558 - val_acc: 0.8821\n",
      "Epoch 13/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.3091 - acc: 0.8768 - val_loss: 0.2961 - val_acc: 0.9049\n",
      "Epoch 14/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2992 - acc: 0.8835 - val_loss: 0.2868 - val_acc: 0.8971\n",
      "Epoch 15/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2932 - acc: 0.8837 - val_loss: 0.2588 - val_acc: 0.8948\n",
      "Epoch 16/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2805 - acc: 0.8891 - val_loss: 0.2824 - val_acc: 0.9115\n",
      "Epoch 17/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2906 - acc: 0.8847 - val_loss: 0.3207 - val_acc: 0.9068\n",
      "Epoch 18/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2805 - acc: 0.8891 - val_loss: 0.3471 - val_acc: 0.9048\n",
      "Epoch 19/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2726 - acc: 0.8906 - val_loss: 0.2903 - val_acc: 0.9097\n",
      "Epoch 20/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2659 - acc: 0.8974 - val_loss: 0.2480 - val_acc: 0.9157\n",
      "Epoch 21/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.2714 - acc: 0.8940 - val_loss: 0.2794 - val_acc: 0.9046\n",
      "Epoch 22/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2725 - acc: 0.8929 - val_loss: 0.2901 - val_acc: 0.9173\n",
      "Epoch 23/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2656 - acc: 0.8949 - val_loss: 0.2929 - val_acc: 0.9062\n",
      "Epoch 24/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2654 - acc: 0.8947 - val_loss: 0.2949 - val_acc: 0.9146\n",
      "Epoch 25/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2607 - acc: 0.8968 - val_loss: 0.2875 - val_acc: 0.9112\n",
      "Epoch 26/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2585 - acc: 0.8979 - val_loss: 0.2465 - val_acc: 0.8954\n",
      "Epoch 27/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2548 - acc: 0.8984 - val_loss: 0.2302 - val_acc: 0.9136\n",
      "Epoch 28/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2554 - acc: 0.8993 - val_loss: 0.3176 - val_acc: 0.9017\n",
      "Epoch 29/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2532 - acc: 0.8992 - val_loss: 0.2990 - val_acc: 0.9131\n",
      "Epoch 30/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2541 - acc: 0.8989 - val_loss: 0.3630 - val_acc: 0.8739\n",
      "Epoch 31/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2575 - acc: 0.8992 - val_loss: 0.2759 - val_acc: 0.8995\n",
      "Epoch 32/50\n",
      "46539/46539 [==============================] - 2s 40us/sample - loss: 0.2545 - acc: 0.9000 - val_loss: 0.3392 - val_acc: 0.9087\n",
      "Epoch 33/50\n",
      "46539/46539 [==============================] - 2s 42us/sample - loss: 0.2554 - acc: 0.8979 - val_loss: 0.2919 - val_acc: 0.9051\n",
      "Epoch 34/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2590 - acc: 0.8963 - val_loss: 0.2720 - val_acc: 0.9086\n",
      "Epoch 35/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2465 - acc: 0.9043 - val_loss: 0.2651 - val_acc: 0.9141\n",
      "Epoch 36/50\n",
      "46539/46539 [==============================] - 2s 43us/sample - loss: 0.2525 - acc: 0.8995 - val_loss: 0.2517 - val_acc: 0.9143\n",
      "Epoch 37/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2466 - acc: 0.9038 - val_loss: 0.2968 - val_acc: 0.9150\n",
      "22162/22162 [==============================] - 2s 76us/sample - loss: 0.2913 - acc: 0.9157\n",
      "Epoch 1/10\n",
      "70917/70917 [==============================] - 4s 50us/sample - loss: 0.2685 - acc: 0.8952\n",
      "Epoch 2/10\n",
      "70917/70917 [==============================] - 3s 43us/sample - loss: 0.2659 - acc: 0.8959\n",
      "Epoch 3/10\n",
      "70917/70917 [==============================] - 4s 56us/sample - loss: 0.2729 - acc: 0.8923\n",
      "Epoch 4/10\n",
      "70917/70917 [==============================] - 4s 60us/sample - loss: 0.2698 - acc: 0.8923\n",
      "Epoch 5/10\n",
      "70917/70917 [==============================] - 3s 49us/sample - loss: 0.2666 - acc: 0.8951\n",
      "Epoch 6/10\n",
      "70917/70917 [==============================] - 4s 50us/sample - loss: 0.2566 - acc: 0.9005\n",
      "Epoch 7/10\n",
      "70917/70917 [==============================] - 4s 51us/sample - loss: 0.2608 - acc: 0.8978\n",
      "Epoch 8/10\n",
      "70917/70917 [==============================] - 4s 55us/sample - loss: 0.2539 - acc: 0.9006\n",
      "Epoch 9/10\n",
      "70917/70917 [==============================] - 3s 46us/sample - loss: 0.2526 - acc: 0.9003\n",
      "Epoch 10/10\n",
      "70917/70917 [==============================] - 3s 44us/sample - loss: 0.2515 - acc: 0.9018\n",
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.5884 - acc: 0.6610 - val_loss: 0.5662 - val_acc: 0.7230\n",
      "Epoch 2/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.5513 - acc: 0.7152 - val_loss: 0.5686 - val_acc: 0.7273\n",
      "Epoch 3/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.5376 - acc: 0.7253 - val_loss: 0.5405 - val_acc: 0.7399\n",
      "Epoch 4/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.5019 - acc: 0.7532 - val_loss: 0.4898 - val_acc: 0.7899\n",
      "Epoch 5/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.4473 - acc: 0.7954 - val_loss: 0.4950 - val_acc: 0.7901\n",
      "Epoch 6/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.4027 - acc: 0.8306 - val_loss: 0.4364 - val_acc: 0.8626\n",
      "Epoch 7/50\n",
      "46539/46539 [==============================] - 3s 69us/sample - loss: 0.3664 - acc: 0.8558 - val_loss: 0.3384 - val_acc: 0.8720\n",
      "Epoch 8/50\n",
      "46539/46539 [==============================] - 3s 68us/sample - loss: 0.3449 - acc: 0.8669 - val_loss: 0.4029 - val_acc: 0.8876\n",
      "Epoch 9/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.3318 - acc: 0.8706 - val_loss: 0.3609 - val_acc: 0.9066\n",
      "Epoch 10/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.3242 - acc: 0.8730 - val_loss: 0.3199 - val_acc: 0.9020\n",
      "Epoch 11/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.3097 - acc: 0.8777 - val_loss: 0.3174 - val_acc: 0.9085\n",
      "Epoch 12/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.3111 - acc: 0.8779 - val_loss: 0.3047 - val_acc: 0.8922\n",
      "Epoch 13/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.3128 - acc: 0.8773 - val_loss: 0.2825 - val_acc: 0.9086\n",
      "Epoch 14/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.3051 - acc: 0.8787 - val_loss: 0.3156 - val_acc: 0.8858\n",
      "Epoch 15/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2852 - acc: 0.8882 - val_loss: 0.3002 - val_acc: 0.9118\n",
      "Epoch 16/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2850 - acc: 0.8882 - val_loss: 0.4212 - val_acc: 0.8830\n",
      "Epoch 17/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2804 - acc: 0.8892 - val_loss: 0.2672 - val_acc: 0.9146\n",
      "Epoch 18/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2775 - acc: 0.8915 - val_loss: 0.2849 - val_acc: 0.9152\n",
      "Epoch 19/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2795 - acc: 0.8912 - val_loss: 0.3238 - val_acc: 0.9067\n",
      "Epoch 20/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2744 - acc: 0.8923 - val_loss: 0.2863 - val_acc: 0.9147\n",
      "Epoch 21/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2683 - acc: 0.8950 - val_loss: 0.2632 - val_acc: 0.9140\n",
      "Epoch 22/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2686 - acc: 0.8955 - val_loss: 0.2765 - val_acc: 0.9067\n",
      "Epoch 23/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2637 - acc: 0.8953 - val_loss: 0.2515 - val_acc: 0.9068\n",
      "Epoch 24/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2678 - acc: 0.8948 - val_loss: 0.2722 - val_acc: 0.9209\n",
      "Epoch 25/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2635 - acc: 0.8968 - val_loss: 0.3321 - val_acc: 0.8853\n",
      "Epoch 26/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2664 - acc: 0.8959 - val_loss: 0.2974 - val_acc: 0.9129\n",
      "Epoch 27/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.2598 - acc: 0.8969 - val_loss: 0.2469 - val_acc: 0.8981\n",
      "Epoch 28/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.2642 - acc: 0.8975 - val_loss: 0.3270 - val_acc: 0.9060\n",
      "Epoch 29/50\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.2649 - acc: 0.8956 - val_loss: 0.3280 - val_acc: 0.9146\n",
      "Epoch 30/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2592 - acc: 0.8995 - val_loss: 0.2519 - val_acc: 0.9083\n",
      "Epoch 31/50\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.2646 - acc: 0.8951 - val_loss: 0.2786 - val_acc: 0.9152\n",
      "Epoch 32/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2570 - acc: 0.8997 - val_loss: 0.2414 - val_acc: 0.9206\n",
      "Epoch 33/50\n",
      "46539/46539 [==============================] - 3s 65us/sample - loss: 0.2604 - acc: 0.8977 - val_loss: 0.2482 - val_acc: 0.9182\n",
      "Epoch 34/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2523 - acc: 0.9021 - val_loss: 0.2247 - val_acc: 0.9146\n",
      "Epoch 35/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2555 - acc: 0.8999 - val_loss: 0.2787 - val_acc: 0.9154\n",
      "Epoch 36/50\n",
      "46539/46539 [==============================] - 3s 71us/sample - loss: 0.2532 - acc: 0.9016 - val_loss: 0.2331 - val_acc: 0.9179\n",
      "Epoch 37/50\n",
      "46539/46539 [==============================] - 3s 69us/sample - loss: 0.2509 - acc: 0.9020 - val_loss: 0.2369 - val_acc: 0.9148\n",
      "Epoch 38/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2521 - acc: 0.9012 - val_loss: 0.2557 - val_acc: 0.9193\n",
      "Epoch 39/50\n",
      "46539/46539 [==============================] - 3s 69us/sample - loss: 0.2553 - acc: 0.9007 - val_loss: 0.2258 - val_acc: 0.9123\n",
      "22162/22162 [==============================] - 2s 73us/sample - loss: 0.2746 - acc: 0.9180\n",
      "Epoch 1/10\n",
      "70917/70917 [==============================] - 3s 45us/sample - loss: 0.2742 - acc: 0.8921\n",
      "Epoch 2/10\n",
      "70917/70917 [==============================] - 3s 48us/sample - loss: 0.2688 - acc: 0.8934\n",
      "Epoch 3/10\n",
      "70917/70917 [==============================] - 4s 52us/sample - loss: 0.2739 - acc: 0.8924\n",
      "Epoch 4/10\n",
      "70917/70917 [==============================] - 3s 46us/sample - loss: 0.2664 - acc: 0.8942\n",
      "Epoch 5/10\n",
      "70917/70917 [==============================] - 3s 46us/sample - loss: 0.2631 - acc: 0.8968\n",
      "Epoch 6/10\n",
      "70917/70917 [==============================] - 3s 44us/sample - loss: 0.2620 - acc: 0.8968\n",
      "Epoch 7/10\n",
      "70917/70917 [==============================] - 3s 39us/sample - loss: 0.2602 - acc: 0.89711s - loss: 0.2607 - acc - ETA: 1s - loss: 0\n",
      "Epoch 8/10\n",
      "70917/70917 [==============================] - 3s 40us/sample - loss: 0.2564 - acc: 0.9000\n",
      "Epoch 9/10\n",
      "70917/70917 [==============================] - 3s 44us/sample - loss: 0.2587 - acc: 0.89720s - loss: 0.25\n",
      "Epoch 10/10\n",
      "70917/70917 [==============================] - 3s 40us/sample - loss: 0.2545 - acc: 0.9011\n",
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.5951 - acc: 0.6528 - val_loss: 0.5916 - val_acc: 0.7208\n",
      "Epoch 2/50\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.5556 - acc: 0.7098 - val_loss: 0.5773 - val_acc: 0.7230\n",
      "Epoch 3/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.5450 - acc: 0.7191 - val_loss: 0.5826 - val_acc: 0.7301\n",
      "Epoch 4/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.5331 - acc: 0.7246 - val_loss: 0.5402 - val_acc: 0.7377\n",
      "Epoch 5/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.4942 - acc: 0.7493 - val_loss: 0.4751 - val_acc: 0.7893\n",
      "Epoch 6/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.4456 - acc: 0.7929 - val_loss: 0.4324 - val_acc: 0.8114\n",
      "Epoch 7/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.4004 - acc: 0.8280 - val_loss: 0.4418 - val_acc: 0.8024\n",
      "Epoch 8/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.3632 - acc: 0.8542 - val_loss: 0.3564 - val_acc: 0.8935\n",
      "Epoch 9/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.3523 - acc: 0.8592 - val_loss: 0.3476 - val_acc: 0.8868\n",
      "Epoch 10/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.3357 - acc: 0.8650 - val_loss: 0.3970 - val_acc: 0.8968\n",
      "Epoch 11/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.3264 - acc: 0.8694 - val_loss: 0.4011 - val_acc: 0.9095\n",
      "Epoch 12/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.3166 - acc: 0.8740 - val_loss: 0.5143 - val_acc: 0.8905\n",
      "Epoch 13/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.3048 - acc: 0.8810 - val_loss: 0.3116 - val_acc: 0.9114\n",
      "Epoch 14/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.3034 - acc: 0.8800 - val_loss: 0.3352 - val_acc: 0.9063\n",
      "Epoch 15/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2990 - acc: 0.8827 - val_loss: 0.3615 - val_acc: 0.9023\n",
      "Epoch 16/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2956 - acc: 0.8863 - val_loss: 0.2819 - val_acc: 0.9056\n",
      "Epoch 17/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2837 - acc: 0.8904 - val_loss: 0.2592 - val_acc: 0.9055\n",
      "Epoch 18/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2846 - acc: 0.8887 - val_loss: 0.3048 - val_acc: 0.8864\n",
      "Epoch 19/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2857 - acc: 0.8895 - val_loss: 0.3039 - val_acc: 0.9109\n",
      "Epoch 20/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2826 - acc: 0.8871 - val_loss: 0.2778 - val_acc: 0.9170\n",
      "Epoch 21/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2766 - acc: 0.8926 - val_loss: 0.2714 - val_acc: 0.9126\n",
      "Epoch 22/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2772 - acc: 0.8932 - val_loss: 0.3079 - val_acc: 0.9063\n",
      "Epoch 23/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.2750 - acc: 0.8925 - val_loss: 0.2671 - val_acc: 0.9163\n",
      "Epoch 24/50\n",
      "46539/46539 [==============================] - 2s 45us/sample - loss: 0.2736 - acc: 0.8940 - val_loss: 0.2740 - val_acc: 0.9147\n",
      "Epoch 25/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.2706 - acc: 0.8949 - val_loss: 0.2384 - val_acc: 0.9149\n",
      "Epoch 26/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.2716 - acc: 0.8935 - val_loss: 0.2728 - val_acc: 0.9198\n",
      "Epoch 27/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2688 - acc: 0.8921 - val_loss: 0.3027 - val_acc: 0.9028\n",
      "Epoch 28/50\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.2718 - acc: 0.8940 - val_loss: 0.2716 - val_acc: 0.9204\n",
      "Epoch 29/50\n",
      "46539/46539 [==============================] - 3s 69us/sample - loss: 0.2725 - acc: 0.8926 - val_loss: 0.2902 - val_acc: 0.9099\n",
      "Epoch 30/50\n",
      "46539/46539 [==============================] - 3s 69us/sample - loss: 0.2769 - acc: 0.8907 - val_loss: 0.2585 - val_acc: 0.9133\n",
      "Epoch 31/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2586 - acc: 0.9012 - val_loss: 0.3168 - val_acc: 0.9179\n",
      "Epoch 32/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2669 - acc: 0.8957 - val_loss: 0.2410 - val_acc: 0.9105\n",
      "Epoch 33/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2640 - acc: 0.8972 - val_loss: 0.3093 - val_acc: 0.9140\n",
      "Epoch 34/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2608 - acc: 0.8985 - val_loss: 0.3710 - val_acc: 0.9131\n",
      "Epoch 35/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2596 - acc: 0.9000 - val_loss: 0.2796 - val_acc: 0.9193\n",
      "Epoch 36/50\n",
      "46539/46539 [==============================] - 3s 65us/sample - loss: 0.2660 - acc: 0.8976 - val_loss: 0.3102 - val_acc: 0.9131\n",
      "Epoch 37/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2621 - acc: 0.8981 - val_loss: 0.2917 - val_acc: 0.9129\n",
      "Epoch 38/50\n",
      "46539/46539 [==============================] - 3s 64us/sample - loss: 0.2638 - acc: 0.8984 - val_loss: 0.3055 - val_acc: 0.9155\n",
      "Epoch 39/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2661 - acc: 0.8973 - val_loss: 0.3163 - val_acc: 0.8854\n",
      "Epoch 40/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2576 - acc: 0.9011 - val_loss: 0.2316 - val_acc: 0.9189\n",
      "Epoch 41/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2567 - acc: 0.9009 - val_loss: 0.2237 - val_acc: 0.9153\n",
      "Epoch 42/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2535 - acc: 0.9042 - val_loss: 0.2996 - val_acc: 0.9206\n",
      "Epoch 43/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2552 - acc: 0.9016 - val_loss: 0.2946 - val_acc: 0.9170\n",
      "Epoch 44/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2536 - acc: 0.9011 - val_loss: 0.2466 - val_acc: 0.9215\n",
      "Epoch 45/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2588 - acc: 0.8994 - val_loss: 0.2970 - val_acc: 0.9047\n",
      "Epoch 46/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2548 - acc: 0.9033 - val_loss: 0.2398 - val_acc: 0.9175\n",
      "Epoch 47/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2516 - acc: 0.9039 - val_loss: 0.2537 - val_acc: 0.9137\n",
      "Epoch 48/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2521 - acc: 0.9023 - val_loss: 0.2660 - val_acc: 0.9163\n",
      "Epoch 49/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2616 - acc: 0.8996 - val_loss: 0.3233 - val_acc: 0.8908\n",
      "Epoch 50/50\n",
      "46539/46539 [==============================] - 2s 54us/sample - loss: 0.2590 - acc: 0.8981 - val_loss: 0.3236 - val_acc: 0.9179\n",
      "22162/22162 [==============================] - 2s 84us/sample - loss: 0.3263 - acc: 0.9135\n",
      "Epoch 1/10\n",
      "70918/70918 [==============================] - 3s 47us/sample - loss: 0.2547 - acc: 0.9006\n",
      "Epoch 2/10\n",
      "70918/70918 [==============================] - 3s 46us/sample - loss: 0.2541 - acc: 0.9027\n",
      "Epoch 3/10\n",
      "70918/70918 [==============================] - 3s 47us/sample - loss: 0.2499 - acc: 0.9044\n",
      "Epoch 4/10\n",
      "70918/70918 [==============================] - 3s 42us/sample - loss: 0.2607 - acc: 0.8999\n",
      "Epoch 5/10\n",
      "70918/70918 [==============================] - 3s 46us/sample - loss: 0.2461 - acc: 0.9055\n",
      "Epoch 6/10\n",
      "70918/70918 [==============================] - 3s 47us/sample - loss: 0.2422 - acc: 0.9079\n",
      "Epoch 7/10\n",
      "70918/70918 [==============================] - 3s 44us/sample - loss: 0.2512 - acc: 0.9025\n",
      "Epoch 8/10\n",
      "70918/70918 [==============================] - 3s 41us/sample - loss: 0.2529 - acc: 0.9033\n",
      "Epoch 9/10\n",
      "70918/70918 [==============================] - 3s 44us/sample - loss: 0.2551 - acc: 0.9008\n",
      "Epoch 10/10\n",
      "70918/70918 [==============================] - 3s 46us/sample - loss: 0.2449 - acc: 0.9066\n",
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/50\n",
      "46539/46539 [==============================] - 3s 67us/sample - loss: 0.5919 - acc: 0.6577 - val_loss: 0.5534 - val_acc: 0.7143\n",
      "Epoch 2/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.5526 - acc: 0.7117 - val_loss: 0.5734 - val_acc: 0.7221\n",
      "Epoch 3/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.5426 - acc: 0.7193 - val_loss: 0.5715 - val_acc: 0.7244\n",
      "Epoch 4/50\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.5223 - acc: 0.7334 - val_loss: 0.5147 - val_acc: 0.7602\n",
      "Epoch 5/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.4805 - acc: 0.7644 - val_loss: 0.5340 - val_acc: 0.7509\n",
      "Epoch 6/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.4300 - acc: 0.8043 - val_loss: 0.4144 - val_acc: 0.8406\n",
      "Epoch 7/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.3907 - acc: 0.8333 - val_loss: 0.3935 - val_acc: 0.8732\n",
      "Epoch 8/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.3589 - acc: 0.8542 - val_loss: 0.4044 - val_acc: 0.8701\n",
      "Epoch 9/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.3418 - acc: 0.8665 - val_loss: 0.3263 - val_acc: 0.9013\n",
      "Epoch 10/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.3276 - acc: 0.8703 - val_loss: 0.3935 - val_acc: 0.8825\n",
      "Epoch 11/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.3212 - acc: 0.8718 - val_loss: 0.3905 - val_acc: 0.8893\n",
      "Epoch 12/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.3085 - acc: 0.8779 - val_loss: 0.3197 - val_acc: 0.8880\n",
      "Epoch 13/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.3023 - acc: 0.8798 - val_loss: 0.3028 - val_acc: 0.8978\n",
      "Epoch 14/50\n",
      "46539/46539 [==============================] - 2s 47us/sample - loss: 0.2917 - acc: 0.8834 - val_loss: 0.2917 - val_acc: 0.9124\n",
      "Epoch 15/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2891 - acc: 0.8841 - val_loss: 0.2998 - val_acc: 0.9111\n",
      "Epoch 16/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2891 - acc: 0.8838 - val_loss: 0.2846 - val_acc: 0.9020\n",
      "Epoch 17/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2837 - acc: 0.8889 - val_loss: 0.3033 - val_acc: 0.9110\n",
      "Epoch 18/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2772 - acc: 0.8889 - val_loss: 0.3267 - val_acc: 0.9062\n",
      "Epoch 19/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2745 - acc: 0.8898 - val_loss: 0.2772 - val_acc: 0.9142\n",
      "Epoch 20/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2738 - acc: 0.8912 - val_loss: 0.3074 - val_acc: 0.9131\n",
      "Epoch 21/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2710 - acc: 0.8905 - val_loss: 0.2970 - val_acc: 0.9102\n",
      "Epoch 22/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2652 - acc: 0.8934 - val_loss: 0.3297 - val_acc: 0.9064\n",
      "Epoch 23/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2705 - acc: 0.8911 - val_loss: 0.3232 - val_acc: 0.9144\n",
      "Epoch 24/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2611 - acc: 0.8954 - val_loss: 0.2466 - val_acc: 0.9020\n",
      "Epoch 25/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2614 - acc: 0.8955 - val_loss: 0.2398 - val_acc: 0.9199\n",
      "Epoch 26/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2625 - acc: 0.8955 - val_loss: 0.2930 - val_acc: 0.9166\n",
      "Epoch 27/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2544 - acc: 0.8992 - val_loss: 0.2680 - val_acc: 0.9095\n",
      "Epoch 28/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2567 - acc: 0.8969 - val_loss: 0.2814 - val_acc: 0.9178\n",
      "Epoch 29/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2579 - acc: 0.8974 - val_loss: 0.2528 - val_acc: 0.9171\n",
      "Epoch 30/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.2562 - acc: 0.8992 - val_loss: 0.3204 - val_acc: 0.8986\n",
      "Epoch 31/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2510 - acc: 0.9000 - val_loss: 0.2606 - val_acc: 0.9108\n",
      "Epoch 32/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2628 - acc: 0.8942 - val_loss: 0.2479 - val_acc: 0.9170\n",
      "Epoch 33/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2565 - acc: 0.8962 - val_loss: 0.2793 - val_acc: 0.9156\n",
      "Epoch 34/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2488 - acc: 0.9022 - val_loss: 0.2673 - val_acc: 0.9150\n",
      "Epoch 35/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2505 - acc: 0.8999 - val_loss: 0.2634 - val_acc: 0.9092\n",
      "Epoch 36/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2458 - acc: 0.9032 - val_loss: 0.2523 - val_acc: 0.9227\n",
      "Epoch 37/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2534 - acc: 0.9000 - val_loss: 0.2386 - val_acc: 0.9203\n",
      "Epoch 38/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2457 - acc: 0.9026 - val_loss: 0.2460 - val_acc: 0.9219\n",
      "Epoch 39/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.2542 - acc: 0.8996 - val_loss: 0.2931 - val_acc: 0.9094\n",
      "Epoch 40/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2499 - acc: 0.8975 - val_loss: 0.2584 - val_acc: 0.9113\n",
      "Epoch 41/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2480 - acc: 0.9002 - val_loss: 0.2230 - val_acc: 0.9220\n",
      "Epoch 42/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2474 - acc: 0.9009 - val_loss: 0.2674 - val_acc: 0.9141\n",
      "Epoch 43/50\n",
      "46539/46539 [==============================] - 3s 64us/sample - loss: 0.2444 - acc: 0.9037 - val_loss: 0.2750 - val_acc: 0.9124\n",
      "Epoch 44/50\n",
      "46539/46539 [==============================] - 3s 70us/sample - loss: 0.2422 - acc: 0.9043 - val_loss: 0.2287 - val_acc: 0.9140\n",
      "Epoch 45/50\n",
      "46539/46539 [==============================] - 3s 64us/sample - loss: 0.2423 - acc: 0.9041 - val_loss: 0.2404 - val_acc: 0.9206\n",
      "Epoch 46/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2411 - acc: 0.9043 - val_loss: 0.2815 - val_acc: 0.9155\n",
      "Epoch 47/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.2439 - acc: 0.9028 - val_loss: 0.2434 - val_acc: 0.9184\n",
      "Epoch 48/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2392 - acc: 0.9057 - val_loss: 0.2482 - val_acc: 0.9183\n",
      "Epoch 49/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2426 - acc: 0.9040 - val_loss: 0.2240 - val_acc: 0.9166\n",
      "Epoch 50/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2405 - acc: 0.9047 - val_loss: 0.3013 - val_acc: 0.9047\n",
      "22162/22162 [==============================] - 2s 83us/sample - loss: 0.3023 - acc: 0.9056\n",
      "Epoch 1/10\n",
      "70918/70918 [==============================] - 4s 55us/sample - loss: 0.2398 - acc: 0.9057\n",
      "Epoch 2/10\n",
      "70918/70918 [==============================] - 4s 54us/sample - loss: 0.2415 - acc: 0.9055\n",
      "Epoch 3/10\n",
      "70918/70918 [==============================] - 4s 54us/sample - loss: 0.2376 - acc: 0.9059\n",
      "Epoch 4/10\n",
      "70918/70918 [==============================] - 5s 65us/sample - loss: 0.2370 - acc: 0.9061\n",
      "Epoch 5/10\n",
      "70918/70918 [==============================] - 5s 71us/sample - loss: 0.2409 - acc: 0.90500s - loss: 0.2412 - acc: 0.904\n",
      "Epoch 6/10\n",
      "70918/70918 [==============================] - 4s 60us/sample - loss: 0.2325 - acc: 0.9091\n",
      "Epoch 7/10\n",
      "70918/70918 [==============================] - 4s 56us/sample - loss: 0.2334 - acc: 0.9091\n",
      "Epoch 8/10\n",
      "70918/70918 [==============================] - 4s 50us/sample - loss: 0.2352 - acc: 0.9075\n",
      "Epoch 9/10\n",
      "70918/70918 [==============================] - 4s 53us/sample - loss: 0.2331 - acc: 0.9077\n",
      "Epoch 10/10\n",
      "70918/70918 [==============================] - 4s 52us/sample - loss: 0.2332 - acc: 0.9087\n",
      "Train on 46539 samples, validate on 19946 samples\n",
      "Epoch 1/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.5926 - acc: 0.6575 - val_loss: 0.5578 - val_acc: 0.7153\n",
      "Epoch 2/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.5517 - acc: 0.7133 - val_loss: 0.5759 - val_acc: 0.7227\n",
      "Epoch 3/50\n",
      "46539/46539 [==============================] - 3s 56us/sample - loss: 0.5382 - acc: 0.7196 - val_loss: 0.5473 - val_acc: 0.7338\n",
      "Epoch 4/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.5010 - acc: 0.7439 - val_loss: 0.4825 - val_acc: 0.7617\n",
      "Epoch 5/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.4573 - acc: 0.7790 - val_loss: 0.4692 - val_acc: 0.8052\n",
      "Epoch 6/50\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.4161 - acc: 0.8127 - val_loss: 0.4005 - val_acc: 0.8309\n",
      "Epoch 7/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.3842 - acc: 0.8353 - val_loss: 0.4447 - val_acc: 0.8653\n",
      "Epoch 8/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.3613 - acc: 0.8522 - val_loss: 0.5600 - val_acc: 0.7840\n",
      "Epoch 9/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.3408 - acc: 0.8645 - val_loss: 0.3496 - val_acc: 0.8856\n",
      "Epoch 10/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.3373 - acc: 0.8636 - val_loss: 0.3738 - val_acc: 0.8839\n",
      "Epoch 11/50\n",
      "46539/46539 [==============================] - 3s 64us/sample - loss: 0.3220 - acc: 0.8726 - val_loss: 0.3813 - val_acc: 0.8953\n",
      "Epoch 12/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.3039 - acc: 0.8789 - val_loss: 0.3358 - val_acc: 0.8956\n",
      "Epoch 13/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.3055 - acc: 0.8767 - val_loss: 0.3717 - val_acc: 0.8883\n",
      "Epoch 14/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2929 - acc: 0.8831 - val_loss: 0.3562 - val_acc: 0.8935\n",
      "Epoch 15/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2951 - acc: 0.8829 - val_loss: 0.3811 - val_acc: 0.8740\n",
      "Epoch 16/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2922 - acc: 0.8829 - val_loss: 0.3387 - val_acc: 0.9076\n",
      "Epoch 17/50\n",
      "46539/46539 [==============================] - 3s 62us/sample - loss: 0.2916 - acc: 0.8828 - val_loss: 0.2936 - val_acc: 0.9080\n",
      "Epoch 18/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2871 - acc: 0.8848 - val_loss: 0.2539 - val_acc: 0.9019\n",
      "Epoch 19/50\n",
      "46539/46539 [==============================] - 3s 68us/sample - loss: 0.2753 - acc: 0.8890 - val_loss: 0.3533 - val_acc: 0.9127\n",
      "Epoch 20/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2755 - acc: 0.8885 - val_loss: 0.3127 - val_acc: 0.9031\n",
      "Epoch 21/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2772 - acc: 0.8881 - val_loss: 0.3378 - val_acc: 0.8883\n",
      "Epoch 22/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2822 - acc: 0.8859 - val_loss: 0.3226 - val_acc: 0.9113\n",
      "Epoch 23/50\n",
      "46539/46539 [==============================] - 3s 66us/sample - loss: 0.2741 - acc: 0.8897 - val_loss: 0.3517 - val_acc: 0.9057\n",
      "Epoch 24/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2676 - acc: 0.8943 - val_loss: 0.4164 - val_acc: 0.8611\n",
      "Epoch 25/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2690 - acc: 0.8927 - val_loss: 0.3096 - val_acc: 0.9076\n",
      "Epoch 26/50\n",
      "46539/46539 [==============================] - 2s 46us/sample - loss: 0.2677 - acc: 0.8943 - val_loss: 0.3694 - val_acc: 0.8950\n",
      "Epoch 27/50\n",
      "46539/46539 [==============================] - 3s 54us/sample - loss: 0.2628 - acc: 0.8939 - val_loss: 0.2850 - val_acc: 0.8945\n",
      "Epoch 28/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2630 - acc: 0.8950 - val_loss: 0.3366 - val_acc: 0.8846\n",
      "Epoch 29/50\n",
      "46539/46539 [==============================] - 2s 48us/sample - loss: 0.2609 - acc: 0.8969 - val_loss: 0.5669 - val_acc: 0.6893\n",
      "Epoch 30/50\n",
      "46539/46539 [==============================] - 3s 61us/sample - loss: 0.2580 - acc: 0.8963 - val_loss: 0.3175 - val_acc: 0.9096\n",
      "Epoch 31/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2622 - acc: 0.8953 - val_loss: 0.3619 - val_acc: 0.8998\n",
      "Epoch 32/50\n",
      "46539/46539 [==============================] - 3s 60us/sample - loss: 0.2620 - acc: 0.8969 - val_loss: 0.2664 - val_acc: 0.9140\n",
      "Epoch 33/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2534 - acc: 0.9010 - val_loss: 0.3468 - val_acc: 0.8966\n",
      "Epoch 34/50\n",
      "46539/46539 [==============================] - 3s 63us/sample - loss: 0.2542 - acc: 0.8987 - val_loss: 0.3319 - val_acc: 0.9108\n",
      "Epoch 35/50\n",
      "46539/46539 [==============================] - 3s 72us/sample - loss: 0.2565 - acc: 0.8976 - val_loss: 0.2831 - val_acc: 0.9018\n",
      "Epoch 36/50\n",
      "46539/46539 [==============================] - 3s 68us/sample - loss: 0.2578 - acc: 0.8980 - val_loss: 0.3254 - val_acc: 0.9071\n",
      "Epoch 37/50\n",
      "46539/46539 [==============================] - 3s 55us/sample - loss: 0.2535 - acc: 0.8992 - val_loss: 0.2943 - val_acc: 0.9123\n",
      "Epoch 38/50\n",
      "46539/46539 [==============================] - 3s 59us/sample - loss: 0.2537 - acc: 0.8989 - val_loss: 0.3548 - val_acc: 0.8940\n",
      "Epoch 39/50\n",
      "46539/46539 [==============================] - 3s 57us/sample - loss: 0.2562 - acc: 0.8985 - val_loss: 0.2951 - val_acc: 0.9151\n",
      "Epoch 40/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2481 - acc: 0.9003 - val_loss: 0.3920 - val_acc: 0.9099\n",
      "Epoch 41/50\n",
      "46539/46539 [==============================] - 3s 58us/sample - loss: 0.2471 - acc: 0.9024 - val_loss: 0.2918 - val_acc: 0.9166\n",
      "Epoch 42/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2478 - acc: 0.9007 - val_loss: 0.3064 - val_acc: 0.9143\n",
      "Epoch 43/50\n",
      "46539/46539 [==============================] - 2s 53us/sample - loss: 0.2481 - acc: 0.9014 - val_loss: 0.2990 - val_acc: 0.9174\n",
      "Epoch 44/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.2453 - acc: 0.9022 - val_loss: 0.4460 - val_acc: 0.8772\n",
      "Epoch 45/50\n",
      "46539/46539 [==============================] - 2s 52us/sample - loss: 0.2442 - acc: 0.9023 - val_loss: 0.3111 - val_acc: 0.9197\n",
      "Epoch 46/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2453 - acc: 0.9022 - val_loss: 0.2871 - val_acc: 0.9140\n",
      "Epoch 47/50\n",
      "46539/46539 [==============================] - 2s 51us/sample - loss: 0.2473 - acc: 0.9024 - val_loss: 0.6675 - val_acc: 0.3410\n",
      "Epoch 48/50\n",
      "46539/46539 [==============================] - 2s 50us/sample - loss: 0.2442 - acc: 0.9020 - val_loss: 0.3982 - val_acc: 0.8961\n",
      "Epoch 49/50\n",
      "46539/46539 [==============================] - 2s 49us/sample - loss: 0.2442 - acc: 0.9035 - val_loss: 0.2836 - val_acc: 0.9156\n",
      "Epoch 50/50\n",
      "46539/46539 [==============================] - 2s 44us/sample - loss: 0.2381 - acc: 0.9053 - val_loss: 0.2755 - val_acc: 0.9137\n",
      "22162/22162 [==============================] - 2s 76us/sample - loss: 0.2774 - acc: 0.9126\n",
      "Epoch 1/10\n",
      "70918/70918 [==============================] - 3s 44us/sample - loss: 0.2451 - acc: 0.9033\n",
      "Epoch 2/10\n",
      "70918/70918 [==============================] - 3s 44us/sample - loss: 0.2411 - acc: 0.9049\n",
      "Epoch 3/10\n",
      "70918/70918 [==============================] - 3s 43us/sample - loss: 0.2393 - acc: 0.9044\n",
      "Epoch 4/10\n",
      "70918/70918 [==============================] - 3s 43us/sample - loss: 0.2400 - acc: 0.9032\n",
      "Epoch 5/10\n",
      "70918/70918 [==============================] - 3s 44us/sample - loss: 0.2371 - acc: 0.9066\n",
      "Epoch 6/10\n",
      "70918/70918 [==============================] - 3s 39us/sample - loss: 0.2372 - acc: 0.9060\n",
      "Epoch 7/10\n",
      "70918/70918 [==============================] - 3s 39us/sample - loss: 0.2386 - acc: 0.9045\n",
      "Epoch 8/10\n",
      "70918/70918 [==============================] - 3s 39us/sample - loss: 0.2349 - acc: 0.9067\n",
      "Epoch 9/10\n",
      "70918/70918 [==============================] - 3s 43us/sample - loss: 0.2389 - acc: 0.9050\n",
      "Epoch 10/10\n",
      "70918/70918 [==============================] - 3s 42us/sample - loss: 0.2365 - acc: 0.9062\n"
     ]
    }
   ],
   "source": [
    "# making predictions based on a five fold cross-validation\n",
    "cv_preds = cross_val_predict(mod, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgZcqFsm5AFT",
    "outputId": "253cd48e-ad5e-4b02-b9a3-b370f9dc6dc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhK6utE3IW9Z",
    "outputId": "10e6682e-26cb-461f-8cb1-a2c1a7aba096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52875  5125]\n",
      " [ 2776 27871]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix of the cross validation results & the actual values\n",
    "cm = confusion_matrix(y, cv_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a695185f08>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 score for the model is: \n",
      " 0.8758543751865876\n"
     ]
    }
   ],
   "source": [
    "f1s = f1_score(y, cv_preds)\n",
    "\n",
    "print('The F1 score for the model is: \\n', f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision-recall score is: 0.84\n",
      "The recall score is: 0.909\n"
     ]
    }
   ],
   "source": [
    "precis = precision_score(y, cv_preds, average='binary')\n",
    "rec = recall_score(y, cv_preds, average='binary')\n",
    "print('The precision-recall score is: {0:0.2f}'.format(precis))\n",
    "print('The recall score is: %.3f' % rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
